[2025-06-11 16:45:21,185] config: lr: 0.001, batch size:8, num epoches:16
[2025-06-11 16:45:21,185] loss: kld
[2025-06-11 16:45:21,185] origin bit
[2025-06-11 16:45:21,185] beta0 used is 25
[2025-06-11 16:45:21,186] Epoch 1
[2025-06-11 16:45:22,540] sft loss: 4.1015625, weighted bit mean: 3.8912811279296875
[2025-06-11 16:45:22,551] bit.grad.mean: -0.000983 | norm: 0.071411
[2025-06-11 16:48:23,620] sft loss: 3.576171875, weighted bit mean: 3.9017246791294644
[2025-06-11 16:48:23,620] bit.grad.mean: -0.000621 | norm: 0.050751
[2025-06-11 16:51:27,563] sft loss: 4.0078125, weighted bit mean: 3.91973876953125
[2025-06-11 16:51:27,563] bit.grad.mean: -0.000887 | norm: 0.051666
[2025-06-11 16:54:31,405] sft loss: 2.234375, weighted bit mean: 3.937312534877232
[2025-06-11 16:54:31,406] bit.grad.mean: -0.001179 | norm: 0.047516
[2025-06-11 16:57:31,260] sft loss: 3.6953125, weighted bit mean: 3.9549952915736606
[2025-06-11 16:57:31,261] bit.grad.mean: -0.000544 | norm: 0.057251
[2025-06-11 17:00:34,804] sft loss: 3.19921875, weighted bit mean: 3.9711783272879466
[2025-06-11 17:00:34,805] bit.grad.mean: -0.000589 | norm: 0.040222
[2025-06-11 17:00:55,926] sft loss: 4.125, weighted bit mean: 3.9729221888950894
[2025-06-11 17:02:07,698] sft loss: 3.521484375, weighted bit mean: 3.9729221888950894
[2025-06-11 17:03:20,531] sft loss: 3.966796875, weighted bit mean: 3.9729221888950894
[2025-06-11 17:04:33,845] sft loss: 2.22265625, weighted bit mean: 3.9729221888950894
[2025-06-11 17:05:45,094] sft loss: 3.67578125, weighted bit mean: 3.9729221888950894
[2025-06-11 17:06:57,627] sft loss: 3.21875, weighted bit mean: 3.9729221888950894
[2025-06-11 17:07:05,645] Epoch 2
[2025-06-11 17:07:06,681] sft loss: 4.125, weighted bit mean: 3.9729221888950894
[2025-06-11 17:07:06,681] bit.grad.mean: -0.001110 | norm: 0.057587
[2025-06-11 17:10:09,492] sft loss: 3.529296875, weighted bit mean: 3.9871978759765625
[2025-06-11 17:10:09,492] bit.grad.mean: -0.000354 | norm: 0.054718
[2025-06-11 17:13:13,262] sft loss: 3.96875, weighted bit mean: 4.002607073102679
[2025-06-11 17:13:13,263] bit.grad.mean: -0.000908 | norm: 0.047058
[2025-06-11 17:16:17,009] sft loss: 2.20703125, weighted bit mean: 4.016865321568081
[2025-06-11 17:16:17,009] bit.grad.mean: -0.000878 | norm: 0.036896
[2025-06-11 17:19:16,668] sft loss: 3.6953125, weighted bit mean: 4.031350272042411
[2025-06-11 17:19:16,668] bit.grad.mean: -0.000267 | norm: 0.055328
[2025-06-11 17:22:20,075] sft loss: 3.205078125, weighted bit mean: 4.045318603515625
[2025-06-11 17:22:20,075] bit.grad.mean: -0.000404 | norm: 0.036682
[2025-06-11 17:22:41,169] sft loss: 4.09765625, weighted bit mean: 4.046875
[2025-06-11 17:23:53,085] sft loss: 3.537109375, weighted bit mean: 4.046875
[2025-06-11 17:25:05,859] sft loss: 3.97265625, weighted bit mean: 4.046875
[2025-06-11 17:26:18,818] sft loss: 2.216796875, weighted bit mean: 4.046875
[2025-06-11 17:27:29,923] sft loss: 3.703125, weighted bit mean: 4.046875
[2025-06-11 17:28:42,285] sft loss: 3.1953125, weighted bit mean: 4.046875
[2025-06-11 17:28:50,253] Epoch 3
[2025-06-11 17:28:51,286] sft loss: 4.09765625, weighted bit mean: 4.046875
[2025-06-11 17:28:51,287] bit.grad.mean: -0.000756 | norm: 0.050720
[2025-06-11 17:31:53,483] sft loss: 3.5625, weighted bit mean: 4.060793195452009
[2025-06-11 17:31:53,483] bit.grad.mean: -0.000473 | norm: 0.047852
[2025-06-11 17:34:56,798] sft loss: 3.984375, weighted bit mean: 4.075419834681919
[2025-06-11 17:34:56,798] bit.grad.mean: -0.000840 | norm: 0.045837
[2025-06-11 17:37:59,900] sft loss: 2.212890625, weighted bit mean: 4.089270455496652
[2025-06-11 17:37:59,900] bit.grad.mean: -0.000873 | norm: 0.035736
[2025-06-11 17:40:59,134] sft loss: 3.712890625, weighted bit mean: 4.102512904575893
[2025-06-11 17:40:59,134] bit.grad.mean: -0.000431 | norm: 0.043121
[2025-06-11 17:44:02,411] sft loss: 3.16796875, weighted bit mean: 4.1150054931640625
[2025-06-11 17:44:02,411] bit.grad.mean: -0.000408 | norm: 0.034088
[2025-06-11 17:44:23,498] sft loss: 4.05859375, weighted bit mean: 4.116311209542411
[2025-06-11 17:45:35,307] sft loss: 3.5703125, weighted bit mean: 4.116311209542411
[2025-06-11 17:46:48,139] sft loss: 3.96484375, weighted bit mean: 4.116311209542411
[2025-06-11 17:48:01,132] sft loss: 2.216796875, weighted bit mean: 4.116311209542411
[2025-06-11 17:49:12,207] sft loss: 3.68359375, weighted bit mean: 4.116311209542411
[2025-06-11 17:50:24,526] sft loss: 3.17578125, weighted bit mean: 4.116311209542411
[2025-06-11 17:50:32,484] Epoch 4
[2025-06-11 17:50:33,523] sft loss: 4.05859375, weighted bit mean: 4.116311209542411
[2025-06-11 17:50:33,523] bit.grad.mean: -0.000519 | norm: 0.047974
[2025-06-11 17:53:35,906] sft loss: 3.556640625, weighted bit mean: 4.126778738839286
[2025-06-11 17:53:35,906] bit.grad.mean: -0.000245 | norm: 0.048157
[2025-06-11 17:56:39,334] sft loss: 3.919921875, weighted bit mean: 4.138519287109375
[2025-06-11 17:56:39,334] bit.grad.mean: -0.000343 | norm: 0.036407
[2025-06-11 17:59:42,731] sft loss: 2.185546875, weighted bit mean: 4.148478916713169
[2025-06-11 17:59:42,731] bit.grad.mean: -0.000764 | norm: 0.028107
[2025-06-11 18:02:41,893] sft loss: 3.6796875, weighted bit mean: 4.1588897705078125
[2025-06-11 18:02:41,893] bit.grad.mean: -0.000298 | norm: 0.033417
[2025-06-11 18:05:45,229] sft loss: 3.130859375, weighted bit mean: 4.169507707868304
[2025-06-11 18:05:45,229] bit.grad.mean: -0.000273 | norm: 0.033997
[2025-06-11 18:06:06,343] sft loss: 4.05859375, weighted bit mean: 4.170475551060268
[2025-06-11 18:07:18,198] sft loss: 3.5703125, weighted bit mean: 4.170475551060268
[2025-06-11 18:08:30,830] sft loss: 3.97265625, weighted bit mean: 4.170475551060268
[2025-06-11 18:09:43,843] sft loss: 2.2109375, weighted bit mean: 4.170475551060268
[2025-06-11 18:10:54,905] sft loss: 3.689453125, weighted bit mean: 4.170475551060268
[2025-06-11 18:12:07,189] sft loss: 3.162109375, weighted bit mean: 4.170475551060268
[2025-06-11 18:12:15,138] Epoch 5
[2025-06-11 18:12:16,170] sft loss: 4.05859375, weighted bit mean: 4.170475551060268
[2025-06-11 18:12:16,171] bit.grad.mean: -0.000489 | norm: 0.048615
[2025-06-11 18:15:18,413] sft loss: 3.5546875, weighted bit mean: 4.179338727678571
[2025-06-11 18:15:18,413] bit.grad.mean: -0.000683 | norm: 0.052887
[2025-06-11 18:18:21,558] sft loss: 3.91796875, weighted bit mean: 4.189566476004464
[2025-06-11 18:18:21,558] bit.grad.mean: -0.000434 | norm: 0.035492
[2025-06-11 18:21:24,951] sft loss: 2.158203125, weighted bit mean: 4.1986083984375
[2025-06-11 18:21:24,951] bit.grad.mean: -0.000632 | norm: 0.023773
[2025-06-11 18:24:24,006] sft loss: 3.6875, weighted bit mean: 4.2069244384765625
[2025-06-11 18:24:24,006] bit.grad.mean: -0.000461 | norm: 0.039703
[2025-06-11 18:27:27,138] sft loss: 3.12109375, weighted bit mean: 4.216223580496652
[2025-06-11 18:27:27,139] bit.grad.mean: -0.000246 | norm: 0.033142
[2025-06-11 18:27:48,215] sft loss: 4.01171875, weighted bit mean: 4.217008318219866
[2025-06-11 18:28:59,913] sft loss: 3.51171875, weighted bit mean: 4.217008318219866
[2025-06-11 18:30:12,496] sft loss: 3.927734375, weighted bit mean: 4.217008318219866
[2025-06-11 18:31:25,482] sft loss: 2.177734375, weighted bit mean: 4.217008318219866
[2025-06-11 18:32:36,391] sft loss: 3.662109375, weighted bit mean: 4.217008318219866
[2025-06-11 18:33:48,586] sft loss: 3.123046875, weighted bit mean: 4.217008318219866
[2025-06-11 18:33:56,521] Epoch 6
[2025-06-11 18:33:57,548] sft loss: 4.01171875, weighted bit mean: 4.217008318219866
[2025-06-11 18:33:57,548] bit.grad.mean: -0.000255 | norm: 0.033844
[2025-06-11 18:36:59,353] sft loss: 3.50390625, weighted bit mean: 4.224945068359375
[2025-06-11 18:36:59,353] bit.grad.mean: -0.000001 | norm: 0.033813
[2025-06-11 18:40:02,149] sft loss: 3.9140625, weighted bit mean: 4.232953752790179
[2025-06-11 18:40:02,149] bit.grad.mean: -0.000278 | norm: 0.033875
[2025-06-11 18:43:05,328] sft loss: 2.166015625, weighted bit mean: 4.240121023995536
[2025-06-11 18:43:05,328] bit.grad.mean: -0.000629 | norm: 0.024414
[2025-06-11 18:46:03,971] sft loss: 3.630859375, weighted bit mean: 4.247813633510044
[2025-06-11 18:46:03,972] bit.grad.mean: -0.000147 | norm: 0.030014
[2025-06-11 18:49:06,679] sft loss: 3.109375, weighted bit mean: 4.2550048828125
[2025-06-11 18:49:06,679] bit.grad.mean: -0.000158 | norm: 0.031189
[2025-06-11 18:49:27,835] sft loss: 4.02734375, weighted bit mean: 4.255929129464286
[2025-06-11 18:50:39,517] sft loss: 3.490234375, weighted bit mean: 4.255929129464286
[2025-06-11 18:51:52,027] sft loss: 3.90625, weighted bit mean: 4.255929129464286
[2025-06-11 18:53:04,882] sft loss: 2.169921875, weighted bit mean: 4.255929129464286
[2025-06-11 18:54:15,719] sft loss: 3.619140625, weighted bit mean: 4.255929129464286
[2025-06-11 18:55:27,877] sft loss: 3.099609375, weighted bit mean: 4.255929129464286
[2025-06-11 18:55:35,810] Epoch 7
[2025-06-11 18:55:36,840] sft loss: 4.02734375, weighted bit mean: 4.255929129464286
[2025-06-11 18:55:36,840] bit.grad.mean: -0.000402 | norm: 0.041779
[2025-06-11 18:58:38,553] sft loss: 3.490234375, weighted bit mean: 4.262246268136161
[2025-06-11 18:58:38,553] bit.grad.mean: 0.000099 | norm: 0.029724
[2025-06-11 19:01:41,343] sft loss: 3.927734375, weighted bit mean: 4.2691192626953125
[2025-06-11 19:01:41,343] bit.grad.mean: -0.000367 | norm: 0.042297
[2025-06-11 19:04:44,088] sft loss: 2.1484375, weighted bit mean: 4.275617327008929
[2025-06-11 19:04:44,088] bit.grad.mean: -0.000477 | norm: 0.023361
[2025-06-11 19:07:42,692] sft loss: 3.662109375, weighted bit mean: 4.281668526785714
[2025-06-11 19:07:42,693] bit.grad.mean: -0.000357 | norm: 0.039673
[2025-06-11 19:10:45,129] sft loss: 3.115234375, weighted bit mean: 4.288491385323661
[2025-06-11 19:10:45,130] bit.grad.mean: -0.000305 | norm: 0.031860
[2025-06-11 19:11:06,106] sft loss: 4.05859375, weighted bit mean: 4.289191109793527
[2025-06-11 19:12:17,791] sft loss: 3.48828125, weighted bit mean: 4.289191109793527
[2025-06-11 19:13:30,254] sft loss: 3.888671875, weighted bit mean: 4.289191109793527
[2025-06-11 19:14:43,061] sft loss: 2.1640625, weighted bit mean: 4.289191109793527
[2025-06-11 19:15:53,928] sft loss: 3.611328125, weighted bit mean: 4.289191109793527
[2025-06-11 19:17:06,250] sft loss: 3.107421875, weighted bit mean: 4.289191109793527
[2025-06-11 19:17:14,190] Epoch 8
[2025-06-11 19:17:15,224] sft loss: 4.05859375, weighted bit mean: 4.289191109793527
[2025-06-11 19:17:15,224] bit.grad.mean: -0.000517 | norm: 0.040955
[2025-06-11 19:20:16,557] sft loss: 3.505859375, weighted bit mean: 4.295006888253348
[2025-06-11 19:20:16,557] bit.grad.mean: -0.000042 | norm: 0.040619
[2025-06-11 19:23:19,073] sft loss: 3.873046875, weighted bit mean: 4.30169677734375
[2025-06-11 19:23:19,073] bit.grad.mean: -0.000096 | norm: 0.028351
[2025-06-11 19:29:26,567] sft loss: 2.146484375, weighted bit mean: 4.307861328125
[2025-06-11 19:29:26,567] bit.grad.mean: -0.000510 | norm: 0.022903
[2025-06-11 19:47:32,035] config: lr: 0.001, batch size:8, num epoches:16
[2025-06-11 19:47:32,035] loss: kld
[2025-06-11 19:47:32,035] origin bit
[2025-06-11 19:47:32,035] beta0 used is 25
[2025-06-11 19:47:32,036] Epoch 1
[2025-06-11 19:47:33,359] sft loss: 4.1015625, weighted bit mean: 3.8912811279296875
[2025-06-11 19:47:33,371] bit.grad.mean: -0.000983 | norm: 0.071411
[2025-06-11 19:50:34,624] sft loss: 3.576171875, weighted bit mean: 3.9017246791294644
[2025-06-11 19:50:34,624] bit.grad.mean: -0.000621 | norm: 0.050751
[2025-06-11 19:53:38,367] sft loss: 4.0078125, weighted bit mean: 3.91973876953125
[2025-06-11 19:53:38,367] bit.grad.mean: -0.000887 | norm: 0.051666
[2025-06-11 19:56:42,378] sft loss: 2.234375, weighted bit mean: 3.937312534877232
[2025-06-11 19:56:42,379] bit.grad.mean: -0.001179 | norm: 0.047516
[2025-06-11 19:59:42,255] sft loss: 3.6953125, weighted bit mean: 3.9549952915736606
[2025-06-11 19:59:42,256] bit.grad.mean: -0.000544 | norm: 0.057251
[2025-06-11 20:02:45,964] sft loss: 3.19921875, weighted bit mean: 3.9711783272879466
[2025-06-11 20:02:45,964] bit.grad.mean: -0.000589 | norm: 0.040222
[2025-06-11 20:03:07,059] sft loss: 4.125, weighted bit mean: 3.9729221888950894
[2025-06-11 20:04:18,614] sft loss: 3.521484375, weighted bit mean: 3.9729221888950894
[2025-06-11 20:05:31,430] sft loss: 3.966796875, weighted bit mean: 3.9729221888950894
[2025-06-11 20:06:44,484] sft loss: 2.22265625, weighted bit mean: 3.9729221888950894
[2025-06-11 20:07:55,856] sft loss: 3.67578125, weighted bit mean: 3.9729221888950894
[2025-06-11 20:09:08,150] sft loss: 3.21875, weighted bit mean: 3.9729221888950894
[2025-06-11 20:09:16,120] epoch 1:ori_model acc:0.771484375, quantized_model acc:0.75244140625 
[2025-06-11 20:09:16,121] Epoch 2
[2025-06-11 20:09:17,164] sft loss: 4.125, weighted bit mean: 3.9729221888950894
[2025-06-11 20:09:17,164] bit.grad.mean: -0.001110 | norm: 0.057587
[2025-06-11 20:12:19,935] sft loss: 3.529296875, weighted bit mean: 3.9871978759765625
[2025-06-11 20:12:19,935] bit.grad.mean: -0.000354 | norm: 0.054718
[2025-06-11 20:15:23,973] sft loss: 3.96875, weighted bit mean: 4.002607073102679
[2025-06-11 20:15:23,973] bit.grad.mean: -0.000908 | norm: 0.047058
[2025-06-11 20:18:28,233] sft loss: 2.20703125, weighted bit mean: 4.016865321568081
[2025-06-11 20:18:28,234] bit.grad.mean: -0.000878 | norm: 0.036896
[2025-06-11 20:21:28,147] sft loss: 3.6953125, weighted bit mean: 4.031350272042411
[2025-06-11 20:21:28,147] bit.grad.mean: -0.000267 | norm: 0.055328
[2025-06-11 20:24:31,814] sft loss: 3.205078125, weighted bit mean: 4.045318603515625
[2025-06-11 20:24:31,814] bit.grad.mean: -0.000404 | norm: 0.036682
[2025-06-11 20:24:52,916] sft loss: 4.09765625, weighted bit mean: 4.046875
[2025-06-11 20:26:04,342] sft loss: 3.537109375, weighted bit mean: 4.046875
[2025-06-11 20:27:17,083] sft loss: 3.97265625, weighted bit mean: 4.046875
[2025-06-11 20:28:29,884] sft loss: 2.216796875, weighted bit mean: 4.046875
[2025-06-11 20:29:40,763] sft loss: 3.703125, weighted bit mean: 4.046875
[2025-06-11 20:30:52,809] sft loss: 3.1953125, weighted bit mean: 4.046875
[2025-06-11 20:31:00,737] epoch 2:ori_model acc:0.771484375, quantized_model acc:0.755859375 
[2025-06-11 20:31:00,737] Epoch 3
[2025-06-11 20:31:01,778] sft loss: 4.09765625, weighted bit mean: 4.046875
[2025-06-11 20:31:01,778] bit.grad.mean: -0.000756 | norm: 0.050720
[2025-06-11 20:34:04,494] sft loss: 3.5625, weighted bit mean: 4.060793195452009
[2025-06-11 20:34:04,494] bit.grad.mean: -0.000473 | norm: 0.047852
[2025-06-11 20:37:08,090] sft loss: 3.984375, weighted bit mean: 4.075419834681919
[2025-06-11 20:37:08,091] bit.grad.mean: -0.000840 | norm: 0.045837
[2025-06-11 20:40:11,887] sft loss: 2.212890625, weighted bit mean: 4.089270455496652
[2025-06-11 20:40:11,887] bit.grad.mean: -0.000873 | norm: 0.035736
[2025-06-11 20:43:11,615] sft loss: 3.712890625, weighted bit mean: 4.102512904575893
[2025-06-11 20:43:11,615] bit.grad.mean: -0.000431 | norm: 0.043121
[2025-06-11 20:46:15,194] sft loss: 3.16796875, weighted bit mean: 4.1150054931640625
[2025-06-11 20:46:15,194] bit.grad.mean: -0.000408 | norm: 0.034088
[2025-06-11 20:46:36,358] sft loss: 4.05859375, weighted bit mean: 4.116311209542411
[2025-06-11 20:47:47,484] sft loss: 3.5703125, weighted bit mean: 4.116311209542411
[2025-06-11 20:48:59,855] sft loss: 3.96484375, weighted bit mean: 4.116311209542411
[2025-06-11 20:50:12,223] sft loss: 2.216796875, weighted bit mean: 4.116311209542411
[2025-06-11 20:51:22,796] sft loss: 3.68359375, weighted bit mean: 4.116311209542411
[2025-06-11 20:52:34,453] sft loss: 3.17578125, weighted bit mean: 4.116311209542411
[2025-06-11 20:52:42,319] epoch 3:ori_model acc:0.771484375, quantized_model acc:0.75927734375 
[2025-06-11 20:52:42,320] Epoch 4
[2025-06-11 20:52:43,353] sft loss: 4.05859375, weighted bit mean: 4.116311209542411
[2025-06-11 20:52:43,353] bit.grad.mean: -0.000519 | norm: 0.047974
[2025-06-11 20:55:45,910] sft loss: 3.556640625, weighted bit mean: 4.126778738839286
[2025-06-11 20:55:45,910] bit.grad.mean: -0.000245 | norm: 0.048157
[2025-06-11 20:58:49,686] sft loss: 3.919921875, weighted bit mean: 4.138519287109375
[2025-06-11 20:58:49,686] bit.grad.mean: -0.000343 | norm: 0.036407
[2025-06-11 21:01:53,562] sft loss: 2.185546875, weighted bit mean: 4.148478916713169
[2025-06-11 21:01:53,562] bit.grad.mean: -0.000764 | norm: 0.028107
[2025-06-11 21:04:52,985] sft loss: 3.6796875, weighted bit mean: 4.1588897705078125
[2025-06-11 21:04:52,985] bit.grad.mean: -0.000298 | norm: 0.033417
[2025-06-11 21:07:56,388] sft loss: 3.130859375, weighted bit mean: 4.169507707868304
[2025-06-11 21:07:56,389] bit.grad.mean: -0.000273 | norm: 0.033997
[2025-06-11 21:08:17,539] sft loss: 4.05859375, weighted bit mean: 4.170475551060268
[2025-06-11 21:09:28,495] sft loss: 3.5703125, weighted bit mean: 4.170475551060268
[2025-06-11 21:10:40,612] sft loss: 3.97265625, weighted bit mean: 4.170475551060268
[2025-06-11 21:11:52,821] sft loss: 2.2109375, weighted bit mean: 4.170475551060268
[2025-06-11 21:13:03,277] sft loss: 3.689453125, weighted bit mean: 4.170475551060268
[2025-06-11 21:14:14,801] sft loss: 3.162109375, weighted bit mean: 4.170475551060268
[2025-06-11 21:14:22,671] epoch 4:ori_model acc:0.771484375, quantized_model acc:0.75439453125 
[2025-06-11 21:14:22,672] Epoch 5
[2025-06-11 21:14:23,707] sft loss: 4.05859375, weighted bit mean: 4.170475551060268
[2025-06-11 21:14:23,707] bit.grad.mean: -0.000489 | norm: 0.048615
[2025-06-11 21:17:26,152] sft loss: 3.5546875, weighted bit mean: 4.179338727678571
[2025-06-11 21:17:26,153] bit.grad.mean: -0.000683 | norm: 0.052887
[2025-06-11 21:20:29,506] sft loss: 3.91796875, weighted bit mean: 4.189566476004464
[2025-06-11 21:20:29,507] bit.grad.mean: -0.000434 | norm: 0.035492
[2025-06-11 21:23:32,915] sft loss: 2.158203125, weighted bit mean: 4.1986083984375
[2025-06-11 21:23:32,915] bit.grad.mean: -0.000632 | norm: 0.023773
[2025-06-11 21:26:32,047] sft loss: 3.6875, weighted bit mean: 4.2069244384765625
[2025-06-11 21:26:32,047] bit.grad.mean: -0.000461 | norm: 0.039703
[2025-06-11 21:29:35,184] sft loss: 3.12109375, weighted bit mean: 4.216223580496652
[2025-06-11 21:29:35,184] bit.grad.mean: -0.000246 | norm: 0.033142
[2025-06-11 21:29:56,271] sft loss: 4.01171875, weighted bit mean: 4.217008318219866
[2025-06-11 21:31:07,217] sft loss: 3.51171875, weighted bit mean: 4.217008318219866
[2025-06-11 21:32:19,312] sft loss: 3.927734375, weighted bit mean: 4.217008318219866
[2025-06-11 21:33:31,449] sft loss: 2.177734375, weighted bit mean: 4.217008318219866
[2025-06-11 21:34:41,852] sft loss: 3.662109375, weighted bit mean: 4.217008318219866
[2025-06-11 21:35:53,220] sft loss: 3.123046875, weighted bit mean: 4.217008318219866
[2025-06-11 21:36:01,049] epoch 5:ori_model acc:0.771484375, quantized_model acc:0.75634765625 
[2025-06-11 21:36:01,049] Epoch 6
[2025-06-11 21:36:02,080] sft loss: 4.01171875, weighted bit mean: 4.217008318219866
[2025-06-11 21:36:02,080] bit.grad.mean: -0.000255 | norm: 0.033844
[2025-06-11 21:39:04,051] sft loss: 3.50390625, weighted bit mean: 4.224945068359375
[2025-06-11 21:39:04,051] bit.grad.mean: -0.000001 | norm: 0.033813
[2025-06-11 21:42:07,141] sft loss: 3.9140625, weighted bit mean: 4.232953752790179
[2025-06-11 21:42:07,142] bit.grad.mean: -0.000278 | norm: 0.033875
[2025-06-11 21:45:10,530] sft loss: 2.166015625, weighted bit mean: 4.240121023995536
[2025-06-11 21:45:10,530] bit.grad.mean: -0.000629 | norm: 0.024414
[2025-06-11 21:48:09,401] sft loss: 3.630859375, weighted bit mean: 4.247813633510044
[2025-06-11 21:48:09,402] bit.grad.mean: -0.000147 | norm: 0.030014
[2025-06-11 21:51:12,192] sft loss: 3.109375, weighted bit mean: 4.2550048828125
[2025-06-11 21:51:12,192] bit.grad.mean: -0.000158 | norm: 0.031189
[2025-06-11 21:51:33,339] sft loss: 4.02734375, weighted bit mean: 4.255929129464286
[2025-06-11 21:52:44,194] sft loss: 3.490234375, weighted bit mean: 4.255929129464286
[2025-06-11 21:53:56,168] sft loss: 3.90625, weighted bit mean: 4.255929129464286
[2025-06-11 21:55:08,197] sft loss: 2.169921875, weighted bit mean: 4.255929129464286
[2025-06-11 21:56:18,508] sft loss: 3.619140625, weighted bit mean: 4.255929129464286
[2025-06-11 21:57:29,861] sft loss: 3.099609375, weighted bit mean: 4.255929129464286
[2025-06-11 21:57:37,688] epoch 6:ori_model acc:0.771484375, quantized_model acc:0.75927734375 
[2025-06-11 21:57:37,689] Epoch 7
[2025-06-11 21:57:38,722] sft loss: 4.02734375, weighted bit mean: 4.255929129464286
[2025-06-11 21:57:38,722] bit.grad.mean: -0.000402 | norm: 0.041779
[2025-06-11 22:00:40,643] sft loss: 3.490234375, weighted bit mean: 4.262246268136161
[2025-06-11 22:00:40,643] bit.grad.mean: 0.000099 | norm: 0.029724
[2025-06-11 22:03:43,631] sft loss: 3.927734375, weighted bit mean: 4.2691192626953125
[2025-06-11 22:03:43,632] bit.grad.mean: -0.000367 | norm: 0.042297
[2025-06-11 22:06:46,811] sft loss: 2.1484375, weighted bit mean: 4.275617327008929
[2025-06-11 22:06:46,812] bit.grad.mean: -0.000477 | norm: 0.023361
[2025-06-11 22:09:45,670] sft loss: 3.662109375, weighted bit mean: 4.281668526785714
[2025-06-11 22:09:45,670] bit.grad.mean: -0.000357 | norm: 0.039673
[2025-06-11 22:12:48,332] sft loss: 3.115234375, weighted bit mean: 4.288491385323661
[2025-06-11 22:12:48,332] bit.grad.mean: -0.000305 | norm: 0.031860
[2025-06-11 22:13:09,339] sft loss: 4.05859375, weighted bit mean: 4.289191109793527
[2025-06-11 22:14:20,224] sft loss: 3.48828125, weighted bit mean: 4.289191109793527
[2025-06-11 22:15:32,340] sft loss: 3.888671875, weighted bit mean: 4.289191109793527
[2025-06-11 22:16:44,479] sft loss: 2.1640625, weighted bit mean: 4.289191109793527
[2025-06-11 22:17:54,797] sft loss: 3.611328125, weighted bit mean: 4.289191109793527
[2025-06-11 22:19:06,358] sft loss: 3.107421875, weighted bit mean: 4.289191109793527
[2025-06-11 22:19:14,174] epoch 7:ori_model acc:0.771484375, quantized_model acc:0.75830078125 
[2025-06-11 22:19:14,175] Epoch 8
[2025-06-11 22:19:15,210] sft loss: 4.05859375, weighted bit mean: 4.289191109793527
[2025-06-11 22:19:15,210] bit.grad.mean: -0.000517 | norm: 0.040955
[2025-06-11 22:22:16,899] sft loss: 3.505859375, weighted bit mean: 4.295006888253348
[2025-06-11 22:22:16,899] bit.grad.mean: -0.000042 | norm: 0.040619
[2025-06-11 22:25:19,785] sft loss: 3.873046875, weighted bit mean: 4.30169677734375
[2025-06-11 22:25:19,785] bit.grad.mean: -0.000096 | norm: 0.028351
[2025-06-11 22:28:22,874] sft loss: 2.146484375, weighted bit mean: 4.307861328125
[2025-06-11 22:28:22,874] bit.grad.mean: -0.000510 | norm: 0.022903
[2025-06-11 22:31:21,290] sft loss: 3.595703125, weighted bit mean: 4.314488002232143
[2025-06-11 22:31:21,291] bit.grad.mean: 0.000002 | norm: 0.028015
[2025-06-11 22:34:23,811] sft loss: 3.087890625, weighted bit mean: 4.320704868861607
[2025-06-11 22:34:23,812] bit.grad.mean: -0.000196 | norm: 0.024124
[2025-06-11 22:34:44,764] sft loss: 4.03515625, weighted bit mean: 4.321232386997768
[2025-06-11 22:35:55,576] sft loss: 3.48046875, weighted bit mean: 4.321232386997768
[2025-06-11 22:37:07,524] sft loss: 3.884765625, weighted bit mean: 4.321232386997768
[2025-06-11 22:38:19,613] sft loss: 2.126953125, weighted bit mean: 4.321232386997768
[2025-06-11 22:39:29,827] sft loss: 3.609375, weighted bit mean: 4.321232386997768
[2025-06-11 22:40:41,064] sft loss: 3.0859375, weighted bit mean: 4.321232386997768
[2025-06-11 22:40:48,884] epoch 8:ori_model acc:0.771484375, quantized_model acc:0.75390625 
[2025-06-11 22:40:48,884] Epoch 9
[2025-06-11 22:40:49,918] sft loss: 4.03515625, weighted bit mean: 4.321232386997768
[2025-06-11 22:40:49,919] bit.grad.mean: -0.000298 | norm: 0.031982
[2025-06-11 22:43:51,758] sft loss: 3.474609375, weighted bit mean: 4.327599661690848
[2025-06-11 22:43:51,758] bit.grad.mean: 0.000079 | norm: 0.026016
[2025-06-11 22:46:54,478] sft loss: 3.908203125, weighted bit mean: 4.3338165283203125
[2025-06-11 22:46:54,478] bit.grad.mean: -0.000432 | norm: 0.045624
[2025-06-11 22:49:57,401] sft loss: 2.146484375, weighted bit mean: 4.339183262416294
[2025-06-11 22:49:57,402] bit.grad.mean: -0.000535 | norm: 0.022522
[2025-06-11 22:52:56,079] sft loss: 3.568359375, weighted bit mean: 4.344968523297991
[2025-06-11 22:52:56,080] bit.grad.mean: 0.000120 | norm: 0.030624
[2025-06-11 22:55:58,656] sft loss: 3.087890625, weighted bit mean: 4.350302559988839
[2025-06-11 22:55:58,656] bit.grad.mean: -0.000174 | norm: 0.028946
[2025-06-11 22:56:19,630] sft loss: 4.0, weighted bit mean: 4.3509979248046875
[2025-06-11 22:57:30,472] sft loss: 3.484375, weighted bit mean: 4.3509979248046875
[2025-06-11 22:58:42,573] sft loss: 3.88671875, weighted bit mean: 4.3509979248046875
[2025-06-11 22:59:54,620] sft loss: 2.13671875, weighted bit mean: 4.3509979248046875
[2025-06-11 23:01:04,926] sft loss: 3.611328125, weighted bit mean: 4.3509979248046875
[2025-06-11 23:02:16,286] sft loss: 3.07421875, weighted bit mean: 4.3509979248046875
[2025-06-11 23:02:24,123] epoch 9:ori_model acc:0.771484375, quantized_model acc:0.7578125 
[2025-06-11 23:02:24,124] Epoch 10
[2025-06-11 23:02:25,162] sft loss: 4.0, weighted bit mean: 4.3509979248046875
[2025-06-11 23:02:25,162] bit.grad.mean: -0.000185 | norm: 0.032654
[2025-06-11 23:05:27,033] sft loss: 3.46875, weighted bit mean: 4.355752127511161
[2025-06-11 23:05:27,034] bit.grad.mean: 0.000094 | norm: 0.026688
[2025-06-11 23:08:29,792] sft loss: 3.859375, weighted bit mean: 4.361461094447544
[2025-06-11 23:08:29,792] bit.grad.mean: 0.000018 | norm: 0.025696
[2025-06-11 23:11:32,711] sft loss: 2.12109375, weighted bit mean: 4.366418021065848
[2025-06-11 23:11:32,712] bit.grad.mean: -0.000417 | norm: 0.020508
[2025-06-11 23:14:31,272] sft loss: 3.6015625, weighted bit mean: 4.371374947684152
[2025-06-11 23:14:31,273] bit.grad.mean: -0.000048 | norm: 0.026810
[2025-06-11 23:17:33,832] sft loss: 3.083984375, weighted bit mean: 4.376290457589286
[2025-06-11 23:17:33,833] bit.grad.mean: -0.000107 | norm: 0.027374
[2025-06-11 23:17:54,793] sft loss: 4.0234375, weighted bit mean: 4.376988002232143
[2025-06-11 23:19:05,546] sft loss: 3.462890625, weighted bit mean: 4.376988002232143
[2025-06-11 23:20:17,305] sft loss: 3.880859375, weighted bit mean: 4.376988002232143
[2025-06-11 23:21:29,356] sft loss: 2.140625, weighted bit mean: 4.376988002232143
[2025-06-11 23:22:39,554] sft loss: 3.6328125, weighted bit mean: 4.376988002232143
[2025-06-11 23:23:50,826] sft loss: 3.0625, weighted bit mean: 4.376988002232143
[2025-06-11 23:23:58,624] epoch 10:ori_model acc:0.771484375, quantized_model acc:0.7607421875 
[2025-06-11 23:23:58,625] Epoch 11
[2025-06-11 23:23:59,662] sft loss: 4.0234375, weighted bit mean: 4.376988002232143
[2025-06-11 23:23:59,663] bit.grad.mean: -0.000323 | norm: 0.037048
[2025-06-11 23:27:01,174] sft loss: 3.46484375, weighted bit mean: 4.382234845842634
[2025-06-11 23:27:01,174] bit.grad.mean: 0.000118 | norm: 0.026138
[2025-06-11 23:30:03,995] sft loss: 3.880859375, weighted bit mean: 4.387259347098214
[2025-06-11 23:30:03,995] bit.grad.mean: -0.000094 | norm: 0.027130
[2025-06-11 23:33:06,721] sft loss: 2.126953125, weighted bit mean: 4.392122541155134
[2025-06-11 23:33:06,721] bit.grad.mean: -0.000518 | norm: 0.021210
[2025-06-11 23:36:05,327] sft loss: 3.603515625, weighted bit mean: 4.397031511579241
[2025-06-11 23:36:05,327] bit.grad.mean: -0.000024 | norm: 0.036621
[2025-06-11 23:39:07,814] sft loss: 3.0703125, weighted bit mean: 4.402400425502232
[2025-06-11 23:39:07,815] bit.grad.mean: -0.000064 | norm: 0.023575
[2025-06-11 23:39:28,732] sft loss: 4.0390625, weighted bit mean: 4.403021676199777
[2025-06-11 23:40:39,451] sft loss: 3.48046875, weighted bit mean: 4.403021676199777
[2025-06-11 23:41:51,262] sft loss: 3.880859375, weighted bit mean: 4.403021676199777
[2025-06-11 23:43:03,090] sft loss: 2.119140625, weighted bit mean: 4.403021676199777
[2025-06-11 23:44:13,255] sft loss: 3.58984375, weighted bit mean: 4.403021676199777
[2025-06-11 23:45:24,486] sft loss: 3.087890625, weighted bit mean: 4.403021676199777
[2025-06-11 23:45:32,298] epoch 11:ori_model acc:0.771484375, quantized_model acc:0.76171875 
[2025-06-11 23:45:32,298] Epoch 12
[2025-06-11 23:45:33,338] sft loss: 4.0390625, weighted bit mean: 4.403021676199777
[2025-06-11 23:45:33,339] bit.grad.mean: -0.000363 | norm: 0.034729
[2025-06-11 23:48:35,160] sft loss: 3.46875, weighted bit mean: 4.408303397042411
[2025-06-11 23:48:35,161] bit.grad.mean: 0.000156 | norm: 0.026550
[2025-06-11 23:51:38,000] sft loss: 3.85546875, weighted bit mean: 4.41412353515625
[2025-06-11 23:51:38,000] bit.grad.mean: 0.000064 | norm: 0.025177
[2025-06-11 23:54:40,871] sft loss: 2.119140625, weighted bit mean: 4.419091360909598
[2025-06-11 23:54:40,871] bit.grad.mean: -0.000434 | norm: 0.018906
[2025-06-11 23:57:39,447] sft loss: 3.5859375, weighted bit mean: 4.4246978759765625
[2025-06-11 23:57:39,447] bit.grad.mean: 0.000139 | norm: 0.025024
[2025-06-12 00:00:41,981] sft loss: 3.095703125, weighted bit mean: 4.430106026785714
[2025-06-12 00:00:41,981] bit.grad.mean: -0.000147 | norm: 0.025543
[2025-06-12 00:01:02,917] sft loss: 4.03515625, weighted bit mean: 4.430884225027902
[2025-06-12 00:02:13,469] sft loss: 3.484375, weighted bit mean: 4.430884225027902
[2025-06-12 00:03:25,057] sft loss: 3.884765625, weighted bit mean: 4.430884225027902
[2025-06-12 00:04:36,778] sft loss: 2.119140625, weighted bit mean: 4.430884225027902
[2025-06-12 00:05:46,610] sft loss: 3.5859375, weighted bit mean: 4.430884225027902
[2025-06-12 00:06:57,674] sft loss: 3.083984375, weighted bit mean: 4.430884225027902
[2025-06-12 00:07:05,463] epoch 12:ori_model acc:0.771484375, quantized_model acc:0.767578125 
[2025-06-12 00:07:05,464] Epoch 13
[2025-06-12 00:07:06,498] sft loss: 4.03515625, weighted bit mean: 4.430884225027902
[2025-06-12 00:07:06,498] bit.grad.mean: -0.000375 | norm: 0.035889
[2025-06-12 00:10:08,081] sft loss: 3.474609375, weighted bit mean: 4.435902186802456
[2025-06-12 00:10:08,082] bit.grad.mean: 0.000113 | norm: 0.025696
[2025-06-12 00:13:10,783] sft loss: 3.841796875, weighted bit mean: 4.4415435791015625
[2025-06-12 00:13:10,783] bit.grad.mean: 0.000184 | norm: 0.025574
[2025-06-12 00:16:13,725] sft loss: 2.16015625, weighted bit mean: 4.446520124162946
[2025-06-12 00:16:13,725] bit.grad.mean: -0.000615 | norm: 0.044495
[2025-06-12 00:19:12,400] sft loss: 3.615234375, weighted bit mean: 4.451575142996652
[2025-06-12 00:19:12,400] bit.grad.mean: -0.000027 | norm: 0.024048
[2025-06-12 00:22:14,987] sft loss: 3.095703125, weighted bit mean: 4.457155500139509
[2025-06-12 00:22:14,987] bit.grad.mean: -0.000088 | norm: 0.023331
[2025-06-12 00:22:35,997] sft loss: 4.01953125, weighted bit mean: 4.457909720284598
[2025-06-12 00:23:46,790] sft loss: 3.478515625, weighted bit mean: 4.457909720284598
[2025-06-12 00:24:58,645] sft loss: 3.853515625, weighted bit mean: 4.457909720284598
[2025-06-12 00:26:10,665] sft loss: 2.130859375, weighted bit mean: 4.457909720284598
[2025-06-12 00:27:20,849] sft loss: 3.619140625, weighted bit mean: 4.457909720284598
[2025-06-12 00:28:32,133] sft loss: 3.103515625, weighted bit mean: 4.457909720284598
[2025-06-12 00:28:39,969] epoch 13:ori_model acc:0.771484375, quantized_model acc:0.7607421875 
[2025-06-12 00:28:39,969] Epoch 14
[2025-06-12 00:28:41,009] sft loss: 4.01953125, weighted bit mean: 4.457909720284598
[2025-06-12 00:28:41,009] bit.grad.mean: -0.000312 | norm: 0.037231
[2025-06-12 00:31:42,513] sft loss: 3.484375, weighted bit mean: 4.463742937360491
[2025-06-12 00:31:42,513] bit.grad.mean: 0.000097 | norm: 0.024216
[2025-06-12 00:34:45,286] sft loss: 3.875, weighted bit mean: 4.469159807477679
[2025-06-12 00:34:45,286] bit.grad.mean: 0.000051 | norm: 0.027817
[2025-06-12 00:37:48,089] sft loss: 2.12109375, weighted bit mean: 4.474005562918527
[2025-06-12 00:37:48,089] bit.grad.mean: -0.000446 | norm: 0.019409
[2025-06-12 00:40:46,587] sft loss: 3.623046875, weighted bit mean: 4.479088919503348
[2025-06-12 00:40:46,587] bit.grad.mean: -0.000035 | norm: 0.023010
[2025-06-12 00:43:49,221] sft loss: 3.1015625, weighted bit mean: 4.484322684151786
[2025-06-12 00:43:49,222] bit.grad.mean: -0.000119 | norm: 0.028198
[2025-06-12 00:44:10,231] sft loss: 3.9921875, weighted bit mean: 4.485185895647321
[2025-06-12 00:45:20,996] sft loss: 3.48046875, weighted bit mean: 4.485185895647321
[2025-06-12 00:46:32,874] sft loss: 3.8515625, weighted bit mean: 4.485185895647321
[2025-06-12 00:47:44,836] sft loss: 2.107421875, weighted bit mean: 4.485185895647321
[2025-06-12 00:48:55,040] sft loss: 3.623046875, weighted bit mean: 4.485185895647321
[2025-06-12 00:50:06,434] sft loss: 3.0859375, weighted bit mean: 4.485185895647321
[2025-06-12 00:50:14,261] epoch 14:ori_model acc:0.771484375, quantized_model acc:0.765625 
[2025-06-12 00:50:14,261] Epoch 15
[2025-06-12 00:50:15,298] sft loss: 3.9921875, weighted bit mean: 4.485185895647321
[2025-06-12 00:50:15,298] bit.grad.mean: -0.000152 | norm: 0.030548
[2025-06-12 00:53:16,798] sft loss: 3.48828125, weighted bit mean: 4.489988054547991
[2025-06-12 00:53:16,798] bit.grad.mean: 0.000086 | norm: 0.026474
[2025-06-12 00:56:19,553] sft loss: 3.865234375, weighted bit mean: 4.495180402483259
[2025-06-12 00:56:19,553] bit.grad.mean: 0.000068 | norm: 0.025604
[2025-06-12 00:59:22,402] sft loss: 2.1171875, weighted bit mean: 4.499860491071429
[2025-06-12 00:59:22,403] bit.grad.mean: -0.000434 | norm: 0.019379
[2025-06-12 01:02:20,861] sft loss: 3.638671875, weighted bit mean: 4.504854474748884
[2025-06-12 01:02:20,861] bit.grad.mean: -0.000221 | norm: 0.031403
[2025-06-12 01:05:23,225] sft loss: 3.11328125, weighted bit mean: 4.509547642299107
[2025-06-12 01:05:23,226] bit.grad.mean: nan | norm: nan
[2025-06-12 11:18:52,870] config: lr: 0.001, batch size:8, num epoches:16
[2025-06-12 11:18:52,870] loss: kld
[2025-06-12 11:18:52,870] origin bit
[2025-06-12 11:18:52,870] beta0 used is 50
[2025-06-12 11:18:52,871] Epoch 1
[2025-06-12 11:18:54,214] sft loss: 4.1015625, weighted bit mean: 3.8912811279296875
[2025-06-12 11:18:54,226] bit.grad.mean: -0.000983 | norm: 0.071411
[2025-06-12 11:21:55,197] sft loss: 3.576171875, weighted bit mean: 3.9017246791294644
[2025-06-12 11:21:55,198] bit.grad.mean: -0.000621 | norm: 0.050751
[2025-06-12 11:24:58,377] sft loss: 4.0078125, weighted bit mean: 3.91973876953125
[2025-06-12 11:24:58,377] bit.grad.mean: -0.000887 | norm: 0.051666
[2025-06-12 11:28:01,762] sft loss: 2.234375, weighted bit mean: 3.937312534877232
[2025-06-12 11:28:01,762] bit.grad.mean: -0.001179 | norm: 0.047516
[2025-06-12 11:31:01,649] sft loss: 3.6953125, weighted bit mean: 3.9549952915736606
[2025-06-12 11:31:01,650] bit.grad.mean: -0.000544 | norm: 0.057251
[2025-06-12 11:34:05,371] sft loss: 3.19921875, weighted bit mean: 3.9711783272879466
[2025-06-12 11:34:05,371] bit.grad.mean: -0.000589 | norm: 0.040222
[2025-06-12 11:34:26,472] sft loss: 4.125, weighted bit mean: 3.9729221888950894
[2025-06-12 11:35:37,503] sft loss: 3.521484375, weighted bit mean: 3.9729221888950894
[2025-06-12 11:36:49,850] sft loss: 3.966796875, weighted bit mean: 3.9729221888950894
[2025-06-12 11:38:02,118] sft loss: 2.22265625, weighted bit mean: 3.9729221888950894
[2025-06-12 11:39:12,906] sft loss: 3.67578125, weighted bit mean: 3.9729221888950894
[2025-06-12 11:40:24,573] sft loss: 3.21875, weighted bit mean: 3.9729221888950894
[2025-06-12 11:40:32,439] epoch 1:ori_model acc:0.771484375, quantized_model acc:0.75244140625 
[2025-06-12 11:40:32,440] Epoch 2
[2025-06-12 11:40:33,472] sft loss: 4.125, weighted bit mean: 3.9729221888950894
[2025-06-12 11:40:33,472] bit.grad.mean: -0.001110 | norm: 0.057587
[2025-06-12 11:43:35,665] sft loss: 3.529296875, weighted bit mean: 3.9871978759765625
[2025-06-12 11:43:35,665] bit.grad.mean: -0.000354 | norm: 0.054718
[2025-06-12 11:46:39,147] sft loss: 3.96875, weighted bit mean: 4.002607073102679
[2025-06-12 11:46:39,147] bit.grad.mean: -0.000908 | norm: 0.047058
[2025-06-12 11:49:42,701] sft loss: 2.20703125, weighted bit mean: 4.016865321568081
[2025-06-12 11:49:42,701] bit.grad.mean: -0.000878 | norm: 0.036896
[2025-06-12 11:52:41,932] sft loss: 3.6953125, weighted bit mean: 4.031350272042411
[2025-06-12 11:52:41,932] bit.grad.mean: -0.000267 | norm: 0.055328
[2025-06-12 11:55:45,437] sft loss: 3.205078125, weighted bit mean: 4.045318603515625
[2025-06-12 11:55:45,437] bit.grad.mean: -0.000404 | norm: 0.036682
[2025-06-12 11:56:06,538] sft loss: 4.09765625, weighted bit mean: 4.046875
[2025-06-12 11:57:17,738] sft loss: 3.537109375, weighted bit mean: 4.046875
[2025-06-12 11:58:29,788] sft loss: 3.97265625, weighted bit mean: 4.046875
[2025-06-12 11:59:41,790] sft loss: 2.216796875, weighted bit mean: 4.046875
[2025-06-12 12:00:52,236] sft loss: 3.703125, weighted bit mean: 4.046875
[2025-06-12 12:02:03,859] sft loss: 3.1953125, weighted bit mean: 4.046875
[2025-06-12 12:02:11,694] epoch 2:ori_model acc:0.771484375, quantized_model acc:0.755859375 
[2025-06-12 12:02:11,695] Epoch 3
[2025-06-12 12:02:12,734] sft loss: 4.09765625, weighted bit mean: 4.046875
[2025-06-12 12:02:12,734] bit.grad.mean: -0.000756 | norm: 0.050720
[2025-06-12 12:05:14,925] sft loss: 3.5625, weighted bit mean: 4.060793195452009
[2025-06-12 12:05:14,926] bit.grad.mean: -0.000473 | norm: 0.047852
[2025-06-12 12:08:18,196] sft loss: 3.984375, weighted bit mean: 4.075419834681919
[2025-06-12 12:08:18,196] bit.grad.mean: -0.000840 | norm: 0.045837
[2025-06-12 12:11:21,527] sft loss: 2.212890625, weighted bit mean: 4.089270455496652
[2025-06-12 12:11:21,527] bit.grad.mean: -0.000873 | norm: 0.035736
[2025-06-12 12:14:20,669] sft loss: 3.712890625, weighted bit mean: 4.102512904575893
[2025-06-12 12:14:20,670] bit.grad.mean: -0.000431 | norm: 0.043121
[2025-06-12 12:17:23,452] sft loss: 3.16796875, weighted bit mean: 4.1150054931640625
[2025-06-12 12:17:23,452] bit.grad.mean: -0.000408 | norm: 0.034088
[2025-06-12 12:17:44,528] sft loss: 4.05859375, weighted bit mean: 4.116311209542411
[2025-06-12 12:18:55,475] sft loss: 3.5703125, weighted bit mean: 4.116311209542411
[2025-06-12 12:20:07,658] sft loss: 3.96484375, weighted bit mean: 4.116311209542411
[2025-06-12 12:21:19,575] sft loss: 2.216796875, weighted bit mean: 4.116311209542411
[2025-06-12 12:22:30,042] sft loss: 3.68359375, weighted bit mean: 4.116311209542411
[2025-06-12 12:23:41,478] sft loss: 3.17578125, weighted bit mean: 4.116311209542411
[2025-06-12 12:23:49,286] epoch 3:ori_model acc:0.771484375, quantized_model acc:0.75927734375 
[2025-06-12 12:23:49,286] Epoch 4
[2025-06-12 12:23:50,326] sft loss: 4.05859375, weighted bit mean: 4.116311209542411
[2025-06-12 12:23:50,326] bit.grad.mean: -0.000519 | norm: 0.047974
[2025-06-12 12:26:52,272] sft loss: 3.556640625, weighted bit mean: 4.126778738839286
[2025-06-12 12:26:52,272] bit.grad.mean: -0.000245 | norm: 0.048157
[2025-06-12 12:29:55,568] sft loss: 3.919921875, weighted bit mean: 4.138519287109375
[2025-06-12 12:29:55,568] bit.grad.mean: -0.000343 | norm: 0.036407
[2025-06-12 12:32:58,767] sft loss: 2.185546875, weighted bit mean: 4.148478916713169
[2025-06-12 12:32:58,767] bit.grad.mean: -0.000764 | norm: 0.028107
[2025-06-12 12:35:57,661] sft loss: 3.6796875, weighted bit mean: 4.1588897705078125
[2025-06-12 12:35:57,661] bit.grad.mean: -0.000298 | norm: 0.033417
[2025-06-12 12:39:00,667] sft loss: 3.130859375, weighted bit mean: 4.169507707868304
[2025-06-12 12:39:00,667] bit.grad.mean: -0.000273 | norm: 0.033997
[2025-06-12 12:39:21,762] sft loss: 4.05859375, weighted bit mean: 4.170475551060268
[2025-06-12 12:40:32,871] sft loss: 3.5703125, weighted bit mean: 4.170475551060268
[2025-06-12 12:41:45,064] sft loss: 3.97265625, weighted bit mean: 4.170475551060268
[2025-06-12 12:42:57,050] sft loss: 2.2109375, weighted bit mean: 4.170475551060268
[2025-06-12 12:44:07,534] sft loss: 3.689453125, weighted bit mean: 4.170475551060268
[2025-06-12 12:45:19,056] sft loss: 3.162109375, weighted bit mean: 4.170475551060268
[2025-06-12 12:45:26,855] epoch 4:ori_model acc:0.771484375, quantized_model acc:0.75439453125 
[2025-06-12 12:45:26,856] Epoch 5
[2025-06-12 12:45:27,888] sft loss: 4.05859375, weighted bit mean: 4.170475551060268
[2025-06-12 12:45:27,888] bit.grad.mean: -0.000489 | norm: 0.048615
[2025-06-12 12:48:30,030] sft loss: 3.5546875, weighted bit mean: 4.179338727678571
[2025-06-12 12:48:30,031] bit.grad.mean: -0.000683 | norm: 0.052887
[2025-06-12 12:51:33,279] sft loss: 3.91796875, weighted bit mean: 4.189566476004464
[2025-06-12 12:51:33,279] bit.grad.mean: -0.000434 | norm: 0.035492
[2025-06-12 12:54:36,628] sft loss: 2.158203125, weighted bit mean: 4.1986083984375
[2025-06-12 12:54:36,628] bit.grad.mean: -0.000632 | norm: 0.023773
[2025-06-12 12:57:35,682] sft loss: 3.6875, weighted bit mean: 4.2069244384765625
[2025-06-12 12:57:35,682] bit.grad.mean: -0.000461 | norm: 0.039703
[2025-06-12 13:00:38,757] sft loss: 3.12109375, weighted bit mean: 4.216223580496652
[2025-06-12 13:00:38,757] bit.grad.mean: -0.000246 | norm: 0.033142
[2025-06-12 13:00:59,804] sft loss: 4.01171875, weighted bit mean: 4.217008318219866
[2025-06-12 13:02:10,858] sft loss: 3.51171875, weighted bit mean: 4.217008318219866
[2025-06-12 13:03:22,938] sft loss: 3.927734375, weighted bit mean: 4.217008318219866
[2025-06-12 13:04:34,982] sft loss: 2.177734375, weighted bit mean: 4.217008318219866
[2025-06-12 13:05:45,416] sft loss: 3.662109375, weighted bit mean: 4.217008318219866
[2025-06-12 13:06:56,971] sft loss: 3.123046875, weighted bit mean: 4.217008318219866
[2025-06-12 13:07:04,789] epoch 5:ori_model acc:0.771484375, quantized_model acc:0.75634765625 
[2025-06-12 13:07:04,789] Epoch 6
[2025-06-12 13:07:05,821] sft loss: 4.01171875, weighted bit mean: 4.217008318219866
[2025-06-12 13:07:05,821] bit.grad.mean: -0.000255 | norm: 0.033844
[2025-06-12 13:10:07,506] sft loss: 3.50390625, weighted bit mean: 4.224945068359375
[2025-06-12 13:10:07,507] bit.grad.mean: -0.000001 | norm: 0.033813
[2025-06-12 13:13:10,374] sft loss: 3.9140625, weighted bit mean: 4.232953752790179
[2025-06-12 13:13:10,375] bit.grad.mean: -0.000278 | norm: 0.033875
[2025-06-12 13:16:13,548] sft loss: 2.166015625, weighted bit mean: 4.240121023995536
[2025-06-12 13:16:13,549] bit.grad.mean: -0.000629 | norm: 0.024414
[2025-06-12 13:19:12,571] sft loss: 3.630859375, weighted bit mean: 4.247813633510044
[2025-06-12 13:19:12,571] bit.grad.mean: -0.000147 | norm: 0.030014
[2025-06-12 13:22:15,312] sft loss: 3.109375, weighted bit mean: 4.2550048828125
[2025-06-12 13:22:15,312] bit.grad.mean: -0.000158 | norm: 0.031189
[2025-06-12 13:22:36,421] sft loss: 4.02734375, weighted bit mean: 4.255929129464286
[2025-06-12 13:23:47,390] sft loss: 3.490234375, weighted bit mean: 4.255929129464286
[2025-06-12 13:24:59,477] sft loss: 3.90625, weighted bit mean: 4.255929129464286
[2025-06-12 13:26:11,341] sft loss: 2.169921875, weighted bit mean: 4.255929129464286
[2025-06-12 13:27:21,608] sft loss: 3.619140625, weighted bit mean: 4.255929129464286
[2025-06-12 13:28:33,000] sft loss: 3.099609375, weighted bit mean: 4.255929129464286
[2025-06-12 13:28:40,808] epoch 6:ori_model acc:0.771484375, quantized_model acc:0.75927734375 
[2025-06-12 13:28:40,808] Epoch 7
[2025-06-12 13:28:41,837] sft loss: 4.02734375, weighted bit mean: 4.255929129464286
[2025-06-12 13:28:41,838] bit.grad.mean: -0.000402 | norm: 0.041779
[2025-06-12 13:31:43,540] sft loss: 3.490234375, weighted bit mean: 4.262246268136161
[2025-06-12 13:31:43,540] bit.grad.mean: 0.000099 | norm: 0.029724
[2025-06-12 13:34:46,299] sft loss: 3.927734375, weighted bit mean: 4.2691192626953125
[2025-06-12 13:34:46,299] bit.grad.mean: -0.000367 | norm: 0.042297
[2025-06-12 13:37:49,312] sft loss: 2.1484375, weighted bit mean: 4.275617327008929
[2025-06-12 13:37:49,312] bit.grad.mean: -0.000477 | norm: 0.023361
[2025-06-12 13:40:48,070] sft loss: 3.662109375, weighted bit mean: 4.281668526785714
[2025-06-12 13:40:48,070] bit.grad.mean: -0.000357 | norm: 0.039673
[2025-06-12 13:43:50,460] sft loss: 3.115234375, weighted bit mean: 4.288491385323661
[2025-06-12 13:43:50,460] bit.grad.mean: -0.000305 | norm: 0.031860
[2025-06-12 13:44:11,447] sft loss: 4.05859375, weighted bit mean: 4.289191109793527
[2025-06-12 13:45:22,398] sft loss: 3.48828125, weighted bit mean: 4.289191109793527
[2025-06-12 13:46:34,360] sft loss: 3.888671875, weighted bit mean: 4.289191109793527
[2025-06-12 13:47:46,231] sft loss: 2.1640625, weighted bit mean: 4.289191109793527
[2025-06-12 13:48:56,613] sft loss: 3.611328125, weighted bit mean: 4.289191109793527
[2025-06-12 13:50:08,031] sft loss: 3.107421875, weighted bit mean: 4.289191109793527
[2025-06-12 13:50:15,799] epoch 7:ori_model acc:0.771484375, quantized_model acc:0.75830078125 
[2025-06-12 13:50:15,800] Epoch 8
[2025-06-12 13:50:16,836] sft loss: 4.05859375, weighted bit mean: 4.289191109793527
[2025-06-12 13:50:16,836] bit.grad.mean: -0.000517 | norm: 0.040955
[2025-06-12 13:53:17,995] sft loss: 3.505859375, weighted bit mean: 4.295006888253348
[2025-06-12 13:53:17,995] bit.grad.mean: -0.000042 | norm: 0.040619
[2025-06-12 13:56:20,339] sft loss: 3.873046875, weighted bit mean: 4.30169677734375
[2025-06-12 13:56:20,340] bit.grad.mean: -0.000096 | norm: 0.028351
[2025-06-12 13:59:22,803] sft loss: 2.146484375, weighted bit mean: 4.307861328125
[2025-06-12 13:59:22,804] bit.grad.mean: -0.000510 | norm: 0.022903
[2025-06-12 14:02:20,826] sft loss: 3.595703125, weighted bit mean: 4.314488002232143
[2025-06-12 14:02:20,826] bit.grad.mean: 0.000002 | norm: 0.028015
[2025-06-12 14:05:22,695] sft loss: 3.087890625, weighted bit mean: 4.320704868861607
[2025-06-12 14:05:22,695] bit.grad.mean: -0.000196 | norm: 0.024124
[2025-06-12 14:05:43,671] sft loss: 4.03515625, weighted bit mean: 4.321232386997768
[2025-06-12 14:06:54,454] sft loss: 3.48046875, weighted bit mean: 4.321232386997768
[2025-06-12 14:08:06,334] sft loss: 3.884765625, weighted bit mean: 4.321232386997768
[2025-06-12 14:09:18,111] sft loss: 2.126953125, weighted bit mean: 4.321232386997768
[2025-06-12 14:10:28,415] sft loss: 3.609375, weighted bit mean: 4.321232386997768
[2025-06-12 14:11:39,746] sft loss: 3.0859375, weighted bit mean: 4.321232386997768
[2025-06-12 14:11:47,530] epoch 8:ori_model acc:0.771484375, quantized_model acc:0.75390625 
[2025-06-12 14:11:47,530] Epoch 9
[2025-06-12 14:11:48,563] sft loss: 4.03515625, weighted bit mean: 4.321232386997768
[2025-06-12 14:11:48,563] bit.grad.mean: -0.000298 | norm: 0.031982
[2025-06-12 14:14:49,865] sft loss: 3.474609375, weighted bit mean: 4.327599661690848
[2025-06-12 14:14:49,866] bit.grad.mean: 0.000079 | norm: 0.026016
[2025-06-12 14:17:52,046] sft loss: 3.908203125, weighted bit mean: 4.3338165283203125
[2025-06-12 14:17:52,046] bit.grad.mean: -0.000432 | norm: 0.045624
[2025-06-12 14:20:54,411] sft loss: 2.146484375, weighted bit mean: 4.339183262416294
[2025-06-12 14:20:54,411] bit.grad.mean: -0.000535 | norm: 0.022522
[2025-06-12 14:23:52,323] sft loss: 3.568359375, weighted bit mean: 4.344968523297991
[2025-06-12 14:23:52,323] bit.grad.mean: 0.000120 | norm: 0.030624
[2025-06-12 14:26:54,307] sft loss: 3.087890625, weighted bit mean: 4.350302559988839
[2025-06-12 14:26:54,307] bit.grad.mean: -0.000174 | norm: 0.028946
[2025-06-12 14:27:15,263] sft loss: 4.0, weighted bit mean: 4.3509979248046875
[2025-06-12 14:28:26,114] sft loss: 3.484375, weighted bit mean: 4.3509979248046875
[2025-06-12 14:29:38,128] sft loss: 3.88671875, weighted bit mean: 4.3509979248046875
[2025-06-12 14:30:50,062] sft loss: 2.13671875, weighted bit mean: 4.3509979248046875
[2025-06-12 14:32:00,434] sft loss: 3.611328125, weighted bit mean: 4.3509979248046875
[2025-06-12 14:33:11,834] sft loss: 3.07421875, weighted bit mean: 4.3509979248046875
[2025-06-12 14:33:19,638] epoch 9:ori_model acc:0.771484375, quantized_model acc:0.7578125 
[2025-06-12 14:33:19,638] Epoch 10
[2025-06-12 14:33:20,670] sft loss: 4.0, weighted bit mean: 4.3509979248046875
[2025-06-12 14:33:20,670] bit.grad.mean: -0.000185 | norm: 0.032654
[2025-06-12 14:36:21,622] sft loss: 3.46875, weighted bit mean: 4.355752127511161
[2025-06-12 14:36:21,622] bit.grad.mean: 0.000094 | norm: 0.026688
[2025-06-12 14:39:23,860] sft loss: 3.859375, weighted bit mean: 4.361461094447544
[2025-06-12 14:39:23,860] bit.grad.mean: 0.000018 | norm: 0.025696
[2025-06-12 14:42:26,356] sft loss: 2.12109375, weighted bit mean: 4.366418021065848
[2025-06-12 14:42:26,357] bit.grad.mean: -0.000417 | norm: 0.020508
[2025-06-12 14:45:24,509] sft loss: 3.6015625, weighted bit mean: 4.371374947684152
[2025-06-12 14:45:24,509] bit.grad.mean: -0.000048 | norm: 0.026810
[2025-06-12 14:48:26,361] sft loss: 3.083984375, weighted bit mean: 4.376290457589286
[2025-06-12 14:48:26,361] bit.grad.mean: -0.000107 | norm: 0.027374
[2025-06-12 14:48:47,252] sft loss: 4.0234375, weighted bit mean: 4.376988002232143
[2025-06-12 14:49:57,981] sft loss: 3.462890625, weighted bit mean: 4.376988002232143
[2025-06-12 14:51:09,680] sft loss: 3.880859375, weighted bit mean: 4.376988002232143
[2025-06-12 14:52:21,481] sft loss: 2.140625, weighted bit mean: 4.376988002232143
[2025-06-12 14:53:31,696] sft loss: 3.6328125, weighted bit mean: 4.376988002232143
[2025-06-12 14:54:43,020] sft loss: 3.0625, weighted bit mean: 4.376988002232143
[2025-06-12 14:54:50,760] epoch 10:ori_model acc:0.771484375, quantized_model acc:0.7607421875 
[2025-06-12 14:54:50,760] Epoch 11
[2025-06-12 14:54:51,788] sft loss: 4.0234375, weighted bit mean: 4.376988002232143
[2025-06-12 14:54:51,788] bit.grad.mean: -0.000323 | norm: 0.037048
[2025-06-12 14:57:52,949] sft loss: 3.46484375, weighted bit mean: 4.382234845842634
[2025-06-12 14:57:52,949] bit.grad.mean: 0.000118 | norm: 0.026138
[2025-06-12 15:00:55,102] sft loss: 3.880859375, weighted bit mean: 4.387259347098214
[2025-06-12 15:00:55,103] bit.grad.mean: -0.000094 | norm: 0.027130
[2025-06-12 15:03:57,443] sft loss: 2.126953125, weighted bit mean: 4.392122541155134
[2025-06-12 15:03:57,443] bit.grad.mean: -0.000518 | norm: 0.021210
[2025-06-12 15:06:55,444] sft loss: 3.603515625, weighted bit mean: 4.397031511579241
[2025-06-12 15:06:55,445] bit.grad.mean: -0.000024 | norm: 0.036621
[2025-06-12 15:09:57,275] sft loss: 3.0703125, weighted bit mean: 4.402400425502232
[2025-06-12 15:09:57,275] bit.grad.mean: -0.000064 | norm: 0.023575
[2025-06-12 15:10:18,125] sft loss: 4.0390625, weighted bit mean: 4.403021676199777
[2025-06-12 15:11:28,816] sft loss: 3.48046875, weighted bit mean: 4.403021676199777
[2025-06-12 15:12:40,538] sft loss: 3.880859375, weighted bit mean: 4.403021676199777
[2025-06-12 15:13:52,142] sft loss: 2.119140625, weighted bit mean: 4.403021676199777
[2025-06-12 15:15:02,391] sft loss: 3.58984375, weighted bit mean: 4.403021676199777
[2025-06-12 15:16:13,736] sft loss: 3.087890625, weighted bit mean: 4.403021676199777
[2025-06-12 15:16:21,504] epoch 11:ori_model acc:0.771484375, quantized_model acc:0.76171875 
[2025-06-12 15:16:21,504] Epoch 12
[2025-06-12 15:16:22,543] sft loss: 4.0390625, weighted bit mean: 4.403021676199777
[2025-06-12 15:16:22,543] bit.grad.mean: -0.000363 | norm: 0.034729
[2025-06-12 15:19:23,763] sft loss: 3.46875, weighted bit mean: 4.408303397042411
[2025-06-12 15:19:23,763] bit.grad.mean: 0.000156 | norm: 0.026550
[2025-06-12 15:22:25,897] sft loss: 3.85546875, weighted bit mean: 4.41412353515625
[2025-06-12 15:22:25,898] bit.grad.mean: 0.000064 | norm: 0.025177
[2025-06-12 15:25:28,347] sft loss: 2.119140625, weighted bit mean: 4.419091360909598
[2025-06-12 15:25:28,347] bit.grad.mean: -0.000434 | norm: 0.018906
[2025-06-12 15:28:26,323] sft loss: 3.5859375, weighted bit mean: 4.4246978759765625
[2025-06-12 15:28:26,323] bit.grad.mean: 0.000139 | norm: 0.025024
[2025-06-12 15:31:28,257] sft loss: 3.095703125, weighted bit mean: 4.430106026785714
[2025-06-12 15:31:28,257] bit.grad.mean: -0.000147 | norm: 0.025543
[2025-06-12 15:31:49,131] sft loss: 4.03515625, weighted bit mean: 4.430884225027902
[2025-06-12 15:32:59,670] sft loss: 3.484375, weighted bit mean: 4.430884225027902
[2025-06-12 15:34:11,226] sft loss: 3.884765625, weighted bit mean: 4.430884225027902
[2025-06-12 15:35:22,765] sft loss: 2.119140625, weighted bit mean: 4.430884225027902
[2025-06-12 15:36:32,804] sft loss: 3.5859375, weighted bit mean: 4.430884225027902
[2025-06-12 15:37:43,920] sft loss: 3.083984375, weighted bit mean: 4.430884225027902
[2025-06-12 15:37:51,678] epoch 12:ori_model acc:0.771484375, quantized_model acc:0.767578125 
[2025-06-12 15:37:51,679] Epoch 13
[2025-06-12 15:37:52,712] sft loss: 4.03515625, weighted bit mean: 4.430884225027902
[2025-06-12 15:37:52,713] bit.grad.mean: -0.000375 | norm: 0.035889
[2025-06-12 15:40:53,696] sft loss: 3.474609375, weighted bit mean: 4.435902186802456
[2025-06-12 15:40:53,696] bit.grad.mean: 0.000113 | norm: 0.025696
[2025-06-12 15:43:55,737] sft loss: 3.841796875, weighted bit mean: 4.4415435791015625
[2025-06-12 15:43:55,737] bit.grad.mean: 0.000184 | norm: 0.025574
[2025-06-12 15:46:58,041] sft loss: 2.16015625, weighted bit mean: 4.446520124162946
[2025-06-12 15:46:58,041] bit.grad.mean: -0.000615 | norm: 0.044495
[2025-06-12 15:49:55,976] sft loss: 3.615234375, weighted bit mean: 4.451575142996652
[2025-06-12 15:49:55,976] bit.grad.mean: -0.000027 | norm: 0.024048
[2025-06-12 15:52:57,876] sft loss: 3.095703125, weighted bit mean: 4.457155500139509
[2025-06-12 15:52:57,876] bit.grad.mean: -0.000088 | norm: 0.023331
[2025-06-12 15:53:18,844] sft loss: 4.01953125, weighted bit mean: 4.457909720284598
[2025-06-12 15:54:29,638] sft loss: 3.478515625, weighted bit mean: 4.457909720284598
[2025-06-12 15:55:41,465] sft loss: 3.853515625, weighted bit mean: 4.457909720284598
[2025-06-12 15:56:53,217] sft loss: 2.130859375, weighted bit mean: 4.457909720284598
[2025-06-12 15:58:03,449] sft loss: 3.619140625, weighted bit mean: 4.457909720284598
[2025-06-12 15:59:14,755] sft loss: 3.103515625, weighted bit mean: 4.457909720284598
[2025-06-12 15:59:22,563] epoch 13:ori_model acc:0.771484375, quantized_model acc:0.7607421875 
[2025-06-12 15:59:22,563] Epoch 14
[2025-06-12 15:59:23,601] sft loss: 4.01953125, weighted bit mean: 4.457909720284598
[2025-06-12 15:59:23,601] bit.grad.mean: -0.000312 | norm: 0.037231
[2025-06-12 16:02:24,586] sft loss: 3.484375, weighted bit mean: 4.463742937360491
[2025-06-12 16:02:24,586] bit.grad.mean: 0.000097 | norm: 0.024216
[2025-06-12 16:05:26,590] sft loss: 3.875, weighted bit mean: 4.469159807477679
[2025-06-12 16:05:26,591] bit.grad.mean: 0.000051 | norm: 0.027817
[2025-06-12 16:08:28,859] sft loss: 2.12109375, weighted bit mean: 4.474005562918527
[2025-06-12 16:08:28,859] bit.grad.mean: -0.000446 | norm: 0.019409
[2025-06-12 16:11:26,842] sft loss: 3.623046875, weighted bit mean: 4.479088919503348
[2025-06-12 16:11:26,842] bit.grad.mean: -0.000035 | norm: 0.023010
[2025-06-12 16:14:28,684] sft loss: 3.1015625, weighted bit mean: 4.484322684151786
[2025-06-12 16:14:28,684] bit.grad.mean: -0.000119 | norm: 0.028198
[2025-06-12 16:14:49,619] sft loss: 3.9921875, weighted bit mean: 4.485185895647321
[2025-06-12 16:16:00,382] sft loss: 3.48046875, weighted bit mean: 4.485185895647321
[2025-06-12 16:17:12,195] sft loss: 3.8515625, weighted bit mean: 4.485185895647321
[2025-06-12 16:18:23,944] sft loss: 2.107421875, weighted bit mean: 4.485185895647321
[2025-06-12 16:19:34,183] sft loss: 3.623046875, weighted bit mean: 4.485185895647321
[2025-06-12 16:20:45,585] sft loss: 3.0859375, weighted bit mean: 4.485185895647321
[2025-06-12 16:20:53,377] epoch 14:ori_model acc:0.771484375, quantized_model acc:0.765625 
[2025-06-12 16:20:53,377] Epoch 15
[2025-06-12 16:20:54,416] sft loss: 3.9921875, weighted bit mean: 4.485185895647321
[2025-06-12 16:20:54,416] bit.grad.mean: -0.000152 | norm: 0.030548
[2025-06-12 16:23:55,338] sft loss: 3.48828125, weighted bit mean: 4.489988054547991
[2025-06-12 16:23:55,338] bit.grad.mean: 0.000086 | norm: 0.026474
[2025-06-12 16:26:57,283] sft loss: 3.865234375, weighted bit mean: 4.495180402483259
[2025-06-12 16:26:57,283] bit.grad.mean: 0.000068 | norm: 0.025604
[2025-06-12 16:29:59,416] sft loss: 2.1171875, weighted bit mean: 4.499860491071429
[2025-06-12 16:29:59,417] bit.grad.mean: -0.000434 | norm: 0.019379
[2025-06-12 16:32:57,268] sft loss: 3.638671875, weighted bit mean: 4.504854474748884
[2025-06-12 16:32:57,268] bit.grad.mean: -0.000221 | norm: 0.031403
[2025-06-12 16:35:59,280] sft loss: 3.11328125, weighted bit mean: 4.509547642299107
[2025-06-12 16:35:59,281] bit.grad.mean: nan | norm: nan
[2025-06-12 17:22:47,067] config: lr: 0.001, batch size:8, num epoches:16
[2025-06-12 17:22:47,068] loss: kld
[2025-06-12 17:22:47,068] origin bit
[2025-06-12 17:22:47,068] beta0 used is 75
[2025-06-12 17:22:47,068] Epoch 1
[2025-06-12 17:22:48,388] sft loss: 4.1015625, weighted bit mean: 3.8912811279296875
[2025-06-12 17:22:48,399] bit.grad.mean: -0.000983 | norm: 0.071411
[2025-06-12 17:25:49,452] sft loss: 3.576171875, weighted bit mean: 3.9017246791294644
[2025-06-12 17:25:49,452] bit.grad.mean: -0.000621 | norm: 0.050751
[2025-06-12 17:28:53,058] sft loss: 4.0078125, weighted bit mean: 3.91973876953125
[2025-06-12 17:28:53,058] bit.grad.mean: -0.000887 | norm: 0.051666
[2025-06-12 17:31:56,558] sft loss: 2.234375, weighted bit mean: 3.937312534877232
[2025-06-12 17:31:56,558] bit.grad.mean: -0.001179 | norm: 0.047516
[2025-06-12 17:34:56,227] sft loss: 3.6953125, weighted bit mean: 3.9549952915736606
[2025-06-12 17:34:56,227] bit.grad.mean: -0.000544 | norm: 0.057251
[2025-06-12 17:37:59,647] sft loss: 3.19921875, weighted bit mean: 3.9711783272879466
[2025-06-12 17:37:59,647] bit.grad.mean: -0.000589 | norm: 0.040222
[2025-06-12 17:38:20,810] sft loss: 4.125, weighted bit mean: 3.9729221888950894
[2025-06-12 17:39:32,723] sft loss: 3.521484375, weighted bit mean: 3.9729221888950894
[2025-06-12 17:40:45,943] sft loss: 3.966796875, weighted bit mean: 3.9729221888950894
[2025-06-12 17:41:59,374] sft loss: 2.22265625, weighted bit mean: 3.9729221888950894
[2025-06-12 17:43:10,991] sft loss: 3.67578125, weighted bit mean: 3.9729221888950894
[2025-06-12 17:44:23,763] sft loss: 3.21875, weighted bit mean: 3.9729221888950894
[2025-06-12 17:44:31,770] epoch 1:ori_model acc:0.771484375, quantized_model acc:0.75244140625 
[2025-06-12 17:44:31,771] Epoch 2
[2025-06-12 17:44:32,811] sft loss: 4.125, weighted bit mean: 3.9729221888950894
[2025-06-12 17:44:32,811] bit.grad.mean: -0.001110 | norm: 0.057587
[2025-06-12 17:47:35,203] sft loss: 3.529296875, weighted bit mean: 3.9871978759765625
[2025-06-12 17:47:35,203] bit.grad.mean: -0.000354 | norm: 0.054718
[2025-06-12 17:50:38,744] sft loss: 3.96875, weighted bit mean: 4.002607073102679
[2025-06-12 17:50:38,744] bit.grad.mean: -0.000908 | norm: 0.047058
[2025-06-12 17:53:42,381] sft loss: 2.20703125, weighted bit mean: 4.016865321568081
[2025-06-12 17:53:42,381] bit.grad.mean: -0.000878 | norm: 0.036896
[2025-06-12 17:56:41,735] sft loss: 3.6953125, weighted bit mean: 4.031350272042411
[2025-06-12 17:56:41,735] bit.grad.mean: -0.000267 | norm: 0.055328
[2025-06-12 17:59:44,788] sft loss: 3.205078125, weighted bit mean: 4.045318603515625
[2025-06-12 17:59:44,788] bit.grad.mean: -0.000404 | norm: 0.036682
[2025-06-12 18:00:05,956] sft loss: 4.09765625, weighted bit mean: 4.046875
[2025-06-12 18:01:17,972] sft loss: 3.537109375, weighted bit mean: 4.046875
[2025-06-12 18:02:31,148] sft loss: 3.97265625, weighted bit mean: 4.046875
[2025-06-12 18:03:44,329] sft loss: 2.216796875, weighted bit mean: 4.046875
[2025-06-12 18:04:55,926] sft loss: 3.703125, weighted bit mean: 4.046875
[2025-06-12 18:06:08,465] sft loss: 3.1953125, weighted bit mean: 4.046875
[2025-06-12 18:06:16,469] epoch 2:ori_model acc:0.771484375, quantized_model acc:0.755859375 
[2025-06-12 18:06:16,469] Epoch 3
[2025-06-12 18:06:17,504] sft loss: 4.09765625, weighted bit mean: 4.046875
[2025-06-12 18:06:17,504] bit.grad.mean: -0.000756 | norm: 0.050720
[2025-06-12 18:09:19,290] sft loss: 3.5625, weighted bit mean: 4.060793195452009
[2025-06-12 18:09:19,291] bit.grad.mean: -0.000473 | norm: 0.047852
[2025-06-12 18:12:22,252] sft loss: 3.984375, weighted bit mean: 4.075419834681919
[2025-06-12 18:12:22,252] bit.grad.mean: -0.000840 | norm: 0.045837
[2025-06-12 18:15:25,225] sft loss: 2.212890625, weighted bit mean: 4.089270455496652
[2025-06-12 18:15:25,225] bit.grad.mean: -0.000873 | norm: 0.035736
[2025-06-12 18:18:24,132] sft loss: 3.712890625, weighted bit mean: 4.102512904575893
[2025-06-12 18:18:24,132] bit.grad.mean: -0.000431 | norm: 0.043121
[2025-06-12 18:21:27,053] sft loss: 3.16796875, weighted bit mean: 4.1150054931640625
[2025-06-12 18:21:27,053] bit.grad.mean: -0.000408 | norm: 0.034088
[2025-06-12 18:21:48,212] sft loss: 4.05859375, weighted bit mean: 4.116311209542411
[2025-06-12 18:23:00,238] sft loss: 3.5703125, weighted bit mean: 4.116311209542411
[2025-06-12 18:24:13,445] sft loss: 3.96484375, weighted bit mean: 4.116311209542411
[2025-06-12 18:25:26,542] sft loss: 2.216796875, weighted bit mean: 4.116311209542411
[2025-06-12 18:26:38,040] sft loss: 3.68359375, weighted bit mean: 4.116311209542411
[2025-06-12 18:27:50,561] sft loss: 3.17578125, weighted bit mean: 4.116311209542411
[2025-06-12 18:27:58,564] epoch 3:ori_model acc:0.771484375, quantized_model acc:0.75927734375 
[2025-06-12 18:27:58,565] Epoch 4
[2025-06-12 18:27:59,598] sft loss: 4.05859375, weighted bit mean: 4.116311209542411
[2025-06-12 18:27:59,599] bit.grad.mean: -0.000519 | norm: 0.047974
[2025-06-12 18:31:01,727] sft loss: 3.556640625, weighted bit mean: 4.126778738839286
[2025-06-12 18:31:01,727] bit.grad.mean: -0.000245 | norm: 0.048157
[2025-06-12 18:34:04,731] sft loss: 3.919921875, weighted bit mean: 4.138519287109375
[2025-06-12 18:34:04,732] bit.grad.mean: -0.000343 | norm: 0.036407
[2025-06-12 18:37:07,789] sft loss: 2.185546875, weighted bit mean: 4.148478916713169
[2025-06-12 18:37:07,789] bit.grad.mean: -0.000764 | norm: 0.028107
[2025-06-12 18:40:06,721] sft loss: 3.6796875, weighted bit mean: 4.1588897705078125
[2025-06-12 18:40:06,721] bit.grad.mean: -0.000298 | norm: 0.033417
[2025-06-12 18:43:09,710] sft loss: 3.130859375, weighted bit mean: 4.169507707868304
[2025-06-12 18:43:09,710] bit.grad.mean: -0.000273 | norm: 0.033997
[2025-06-12 18:43:30,859] sft loss: 4.05859375, weighted bit mean: 4.170475551060268
[2025-06-12 18:44:42,854] sft loss: 3.5703125, weighted bit mean: 4.170475551060268
[2025-06-12 18:45:55,945] sft loss: 3.97265625, weighted bit mean: 4.170475551060268
[2025-06-12 18:47:08,990] sft loss: 2.2109375, weighted bit mean: 4.170475551060268
[2025-06-12 18:48:20,468] sft loss: 3.689453125, weighted bit mean: 4.170475551060268
[2025-06-12 18:49:32,973] sft loss: 3.162109375, weighted bit mean: 4.170475551060268
[2025-06-12 18:49:40,976] epoch 4:ori_model acc:0.771484375, quantized_model acc:0.75439453125 
[2025-06-12 18:49:40,976] Epoch 5
[2025-06-12 18:49:42,012] sft loss: 4.05859375, weighted bit mean: 4.170475551060268
[2025-06-12 18:49:42,012] bit.grad.mean: -0.000489 | norm: 0.048615
[2025-06-12 18:52:44,022] sft loss: 3.5546875, weighted bit mean: 4.179338727678571
[2025-06-12 18:52:44,023] bit.grad.mean: -0.000683 | norm: 0.052887
[2025-06-12 18:55:46,908] sft loss: 3.91796875, weighted bit mean: 4.189566476004464
[2025-06-12 18:55:46,908] bit.grad.mean: -0.000434 | norm: 0.035492
[2025-06-12 18:58:49,923] sft loss: 2.158203125, weighted bit mean: 4.1986083984375
[2025-06-12 18:58:49,924] bit.grad.mean: -0.000632 | norm: 0.023773
[2025-06-12 19:01:48,872] sft loss: 3.6875, weighted bit mean: 4.2069244384765625
[2025-06-12 19:01:48,872] bit.grad.mean: -0.000461 | norm: 0.039703
[2025-06-12 19:04:51,631] sft loss: 3.12109375, weighted bit mean: 4.216223580496652
[2025-06-12 19:04:51,631] bit.grad.mean: -0.000246 | norm: 0.033142
[2025-06-12 19:05:12,732] sft loss: 4.01171875, weighted bit mean: 4.217008318219866
[2025-06-12 19:06:24,681] sft loss: 3.51171875, weighted bit mean: 4.217008318219866
[2025-06-12 19:07:37,674] sft loss: 3.927734375, weighted bit mean: 4.217008318219866
[2025-06-12 19:08:50,739] sft loss: 2.177734375, weighted bit mean: 4.217008318219866
[2025-06-12 19:10:02,122] sft loss: 3.662109375, weighted bit mean: 4.217008318219866
[2025-06-12 19:11:14,511] sft loss: 3.123046875, weighted bit mean: 4.217008318219866
[2025-06-12 19:11:22,489] epoch 5:ori_model acc:0.771484375, quantized_model acc:0.75634765625 
[2025-06-12 19:11:22,489] Epoch 6
[2025-06-12 19:11:23,518] sft loss: 4.01171875, weighted bit mean: 4.217008318219866
[2025-06-12 19:11:23,518] bit.grad.mean: -0.000255 | norm: 0.033844
[2025-06-12 19:14:25,254] sft loss: 3.50390625, weighted bit mean: 4.224945068359375
[2025-06-12 19:14:25,254] bit.grad.mean: -0.000001 | norm: 0.033813
[2025-06-12 19:17:27,585] sft loss: 3.9140625, weighted bit mean: 4.232953752790179
[2025-06-12 19:17:27,585] bit.grad.mean: -0.000278 | norm: 0.033875
[2025-06-12 19:20:30,584] sft loss: 2.166015625, weighted bit mean: 4.240121023995536
[2025-06-12 19:20:30,584] bit.grad.mean: -0.000629 | norm: 0.024414
[2025-06-12 19:23:28,774] sft loss: 3.630859375, weighted bit mean: 4.247813633510044
[2025-06-12 19:23:28,774] bit.grad.mean: -0.000147 | norm: 0.030014
[2025-06-12 19:26:31,071] sft loss: 3.109375, weighted bit mean: 4.2550048828125
[2025-06-12 19:26:31,071] bit.grad.mean: -0.000158 | norm: 0.031189
[2025-06-12 19:26:52,268] sft loss: 4.02734375, weighted bit mean: 4.255929129464286
[2025-06-12 19:28:04,171] sft loss: 3.490234375, weighted bit mean: 4.255929129464286
[2025-06-12 19:29:17,148] sft loss: 3.90625, weighted bit mean: 4.255929129464286
[2025-06-12 19:30:30,190] sft loss: 2.169921875, weighted bit mean: 4.255929129464286
[2025-06-12 19:31:41,480] sft loss: 3.619140625, weighted bit mean: 4.255929129464286
[2025-06-12 19:32:53,906] sft loss: 3.099609375, weighted bit mean: 4.255929129464286
[2025-06-12 19:33:01,883] epoch 6:ori_model acc:0.771484375, quantized_model acc:0.75927734375 
[2025-06-12 19:33:01,883] Epoch 7
[2025-06-12 19:33:02,912] sft loss: 4.02734375, weighted bit mean: 4.255929129464286
[2025-06-12 19:33:02,912] bit.grad.mean: -0.000402 | norm: 0.041779
[2025-06-12 19:36:04,304] sft loss: 3.490234375, weighted bit mean: 4.262246268136161
[2025-06-12 19:36:04,304] bit.grad.mean: 0.000099 | norm: 0.029724
[2025-06-12 19:39:06,824] sft loss: 3.927734375, weighted bit mean: 4.2691192626953125
[2025-06-12 19:39:06,824] bit.grad.mean: -0.000367 | norm: 0.042297
[2025-06-12 19:42:09,695] sft loss: 2.1484375, weighted bit mean: 4.275617327008929
[2025-06-12 19:42:09,695] bit.grad.mean: -0.000477 | norm: 0.023361

[2025-06-12 19:48:03,878] config: lr: 0.001, batch size:8, num epoches:16
[2025-06-12 19:48:03,878] loss: kld
[2025-06-12 19:48:03,878] origin bit
[2025-06-12 19:48:03,878] beta0 used is 100
[2025-06-12 19:48:03,881] Epoch 1
[2025-06-12 19:48:05,599] sft loss: 4.1015625, weighted bit mean: 3.8912811279296875
[2025-06-12 19:48:05,610] bit.grad.mean: 0.254150 | norm: 4.281250
[2025-06-12 19:48:05,610] sft_loss.grad.mean: -0.000983 | norm: 0.071411
[2025-06-12 19:50:33,097] config: lr: 0.001, batch size:8, num epoches:16
[2025-06-12 19:50:33,097] loss: kld
[2025-06-12 19:50:33,098] origin bit
[2025-06-12 19:50:33,098] beta0 used is 100
[2025-06-12 19:50:33,118] Epoch 1
[2025-06-12 19:50:34,820] sft loss: 4.1015625, weighted bit mean: 3.8912811279296875
[2025-06-12 19:50:34,831] bit.grad.mean: 0.152100 | norm: 2.562500
[2025-06-12 19:50:34,831] sft_loss.grad.mean: -0.000983 | norm: 0.071411
[2025-06-12 19:54:16,904] sft loss: 3.724609375, weighted bit mean: 3.8639744349888394
[2025-06-12 19:54:16,904] bit.grad.mean: 0.148926 | norm: 2.531250
[2025-06-12 19:54:16,905] sft_loss.grad.mean: -0.004158 | norm: 0.183228
[2025-06-12 19:58:01,003] sft loss: 4.296875, weighted bit mean: 3.814540318080357
[2025-06-12 19:58:01,004] bit.grad.mean: 0.150269 | norm: 2.533203
[2025-06-12 19:58:01,004] sft_loss.grad.mean: -0.002831 | norm: 0.102356
[2025-06-12 20:01:45,431] sft loss: 2.55078125, weighted bit mean: 3.764990670340402
[2025-06-12 20:01:45,431] bit.grad.mean: 0.146362 | norm: 2.474609
[2025-06-12 20:01:45,431] sft_loss.grad.mean: -0.006630 | norm: 0.184326
[2025-06-12 20:05:24,721] sft loss: 4.13671875, weighted bit mean: 3.7158115931919644
[2025-06-12 20:05:24,721] bit.grad.mean: 0.147827 | norm: 2.503906
[2025-06-12 20:05:24,721] sft_loss.grad.mean: -0.005180 | norm: 0.158081
[2025-06-12 20:09:08,171] sft loss: 3.697265625, weighted bit mean: 3.6665213448660716
[2025-06-12 20:09:08,171] bit.grad.mean: 0.145630 | norm: 2.482422
[2025-06-12 20:09:08,171] sft_loss.grad.mean: -0.007465 | norm: 0.246704
[2025-06-12 20:09:33,521] sft loss: 4.49609375, weighted bit mean: 3.6605028424944197
[2025-06-12 20:10:45,017] sft loss: 3.892578125, weighted bit mean: 3.6605028424944197
[2025-06-12 20:11:57,330] sft loss: 4.53125, weighted bit mean: 3.6605028424944197
[2025-06-12 20:13:09,842] sft loss: 2.619140625, weighted bit mean: 3.6605028424944197
[2025-06-12 20:14:20,830] sft loss: 4.1796875, weighted bit mean: 3.6605028424944197
[2025-06-12 20:15:32,807] sft loss: 3.65234375, weighted bit mean: 3.6605028424944197
[2025-06-12 20:15:40,818] epoch 1:ori_model acc:0.771484375, quantized_model acc:0.72509765625 
[2025-06-12 20:15:40,818] Epoch 2
[2025-06-12 20:15:42,211] sft loss: 4.49609375, weighted bit mean: 3.6605028424944197
[2025-06-12 20:15:42,212] bit.grad.mean: 0.148193 | norm: 2.515625
[2025-06-12 20:15:42,212] sft_loss.grad.mean: -0.004894 | norm: 0.154053
[2025-06-12 20:19:24,931] sft loss: 4.0234375, weighted bit mean: 3.611596243722098
[2025-06-12 20:19:24,931] bit.grad.mean: 0.145386 | norm: 2.480469
[2025-06-12 20:19:24,931] sft_loss.grad.mean: -0.007675 | norm: 0.325195
[2025-06-12 20:23:08,785] sft loss: 4.640625, weighted bit mean: 3.563594273158482
[2025-06-12 20:23:08,785] bit.grad.mean: 0.144409 | norm: 2.447266
[2025-06-12 20:23:08,785] sft_loss.grad.mean: -0.008621 | norm: 0.270508
[2025-06-12 20:26:52,905] sft loss: 2.798828125, weighted bit mean: 3.515352521623884
[2025-06-12 20:26:52,905] bit.grad.mean: 0.139282 | norm: 2.419922
[2025-06-12 20:26:52,905] sft_loss.grad.mean: -0.013786 | norm: 0.546387
[2025-06-12 20:30:31,982] sft loss: 4.3359375, weighted bit mean: 3.4682464599609375
[2025-06-12 20:30:31,982] bit.grad.mean: 0.145752 | norm: 2.472656
[2025-06-12 20:30:31,982] sft_loss.grad.mean: -0.007309 | norm: 0.252197
[2025-06-12 20:34:15,597] sft loss: 3.94140625, weighted bit mean: 3.4200352260044644
[2025-06-12 20:34:15,597] bit.grad.mean: 0.137695 | norm: 2.398438
[2025-06-12 20:34:15,597] sft_loss.grad.mean: -0.015358 | norm: 0.565430
[2025-06-12 20:34:41,034] sft loss: 4.8203125, weighted bit mean: 3.414369855608259
[2025-06-12 20:35:52,267] sft loss: 4.33984375, weighted bit mean: 3.414369855608259
[2025-06-12 20:37:04,463] sft loss: 4.80078125, weighted bit mean: 3.414369855608259
[2025-06-12 20:38:16,642] sft loss: 2.869140625, weighted bit mean: 3.414369855608259
[2025-06-12 20:39:27,359] sft loss: 4.34375, weighted bit mean: 3.414369855608259
[2025-06-12 20:40:38,981] sft loss: 3.95703125, weighted bit mean: 3.414369855608259
[2025-06-12 20:40:46,922] epoch 2:ori_model acc:0.771484375, quantized_model acc:0.69140625 
[2025-06-12 20:40:46,923] Epoch 3
[2025-06-12 20:40:48,320] sft loss: 4.8203125, weighted bit mean: 3.414369855608259
[2025-06-12 20:40:48,321] bit.grad.mean: 0.144897 | norm: 2.464844
[2025-06-12 20:40:48,321] sft_loss.grad.mean: -0.008118 | norm: 0.304199
[2025-06-12 20:44:30,402] sft loss: 4.2265625, weighted bit mean: 3.3666229248046875
[2025-06-12 20:44:30,402] bit.grad.mean: 0.143188 | norm: 2.437500
[2025-06-12 20:44:30,402] sft_loss.grad.mean: -0.009857 | norm: 0.309570
[2025-06-12 20:48:13,738] sft loss: 4.796875, weighted bit mean: 3.318974086216518
[2025-06-12 20:48:13,738] bit.grad.mean: 0.142822 | norm: 2.435547
[2025-06-12 20:48:13,738] sft_loss.grad.mean: -0.010254 | norm: 0.304688
[2025-06-12 20:51:57,233] sft loss: 2.94921875, weighted bit mean: 3.271665300641741
[2025-06-12 20:51:57,233] bit.grad.mean: 0.138428 | norm: 2.365234
[2025-06-12 20:51:57,234] sft_loss.grad.mean: -0.014641 | norm: 0.383545
[2025-06-13 13:56:26,523] config: lr: 0.001, batch size:8, num epoches:16
[2025-06-13 13:56:26,523] loss: kld
[2025-06-13 13:56:26,523] origin bit
[2025-06-13 13:56:26,524] Epoch 1
[2025-06-13 13:56:28,241] sft loss: 4.1484375, weighted bit mean: 3.5423409598214284
[2025-06-13 13:56:28,252] bit.grad.mean: -0.001170 | norm: 0.089478
[2025-06-13 13:56:28,252] sft_loss.grad.mean: -0.001680 | norm: 0.092224
[2025-06-13 14:00:09,807] sft loss: 3.603515625, weighted bit mean: 3.548494611467634
[2025-06-13 14:00:09,807] bit.grad.mean: -0.000238 | norm: 0.066162
[2025-06-13 14:00:09,807] sft_loss.grad.mean: -0.000748 | norm: 0.067383
[2025-06-13 14:03:54,017] sft loss: 3.9921875, weighted bit mean: 3.5576084681919644
[2025-06-13 14:03:54,018] bit.grad.mean: -0.000540 | norm: 0.060791
[2025-06-13 14:03:54,018] sft_loss.grad.mean: -0.001051 | norm: 0.062988
[2025-06-13 14:07:38,453] sft loss: 2.26171875, weighted bit mean: 3.5672454833984375
[2025-06-13 14:07:38,453] bit.grad.mean: -0.001307 | norm: 0.050781
[2025-06-13 14:07:38,453] sft_loss.grad.mean: -0.001817 | norm: 0.055084
[2025-06-13 14:11:17,907] sft loss: 3.640625, weighted bit mean: 3.5772792271205356
[2025-06-13 14:11:17,907] bit.grad.mean: -0.000374 | norm: 0.055756
[2025-06-13 14:11:17,907] sft_loss.grad.mean: -0.000884 | norm: 0.057007
[2025-06-13 14:15:01,768] sft loss: 3.224609375, weighted bit mean: 3.5857696533203125
[2025-06-13 14:15:01,768] bit.grad.mean: -0.000686 | norm: 0.049835
[2025-06-13 14:15:01,769] sft_loss.grad.mean: -0.001196 | norm: 0.052551
[2025-06-13 14:15:27,193] sft loss: 4.0859375, weighted bit mean: 3.586667742047991
[2025-06-13 14:16:38,732] sft loss: 3.580078125, weighted bit mean: 3.586667742047991
[2025-06-13 14:17:51,140] sft loss: 4.015625, weighted bit mean: 3.586667742047991
[2025-06-13 14:19:03,678] sft loss: 2.271484375, weighted bit mean: 3.586667742047991
[2025-06-13 14:20:14,748] sft loss: 3.6328125, weighted bit mean: 3.586667742047991
[2025-06-13 14:21:26,728] sft loss: 3.23828125, weighted bit mean: 3.586667742047991
[2025-06-13 14:21:34,735] epoch 1:ori_model acc:0.771484375, quantized_model acc:0.7451171875 
[2025-06-13 14:21:34,735] Epoch 2
[2025-06-13 14:21:36,129] sft loss: 4.0859375, weighted bit mean: 3.586667742047991
[2025-06-13 14:21:36,130] bit.grad.mean: -0.000814 | norm: 0.057434
[2025-06-13 14:21:36,130] sft_loss.grad.mean: -0.001325 | norm: 0.059540
[2025-06-13 14:25:19,030] sft loss: 3.544921875, weighted bit mean: 3.5939767020089284
[2025-06-13 14:25:19,031] bit.grad.mean: -0.000021 | norm: 0.049957
[2025-06-13 14:25:19,031] sft_loss.grad.mean: -0.000531 | norm: 0.050964
[2025-06-13 14:29:05,304] sft loss: 3.939453125, weighted bit mean: 3.6002633231026784
[2025-06-13 14:29:05,304] bit.grad.mean: -0.000289 | norm: 0.051239
[2025-06-13 14:29:05,305] sft_loss.grad.mean: -0.000799 | norm: 0.052612
[2025-06-13 14:32:49,423] sft loss: 2.23828125, weighted bit mean: 3.6078600202287947
[2025-06-13 14:32:49,423] bit.grad.mean: -0.000725 | norm: 0.037842
[2025-06-13 14:32:49,423] sft_loss.grad.mean: -0.001235 | norm: 0.041168
[2025-06-13 14:36:28,426] sft loss: 3.6484375, weighted bit mean: 3.615142822265625
[2025-06-13 14:36:28,426] bit.grad.mean: 0.000083 | norm: 0.050781
[2025-06-13 14:36:28,426] sft_loss.grad.mean: -0.000427 | norm: 0.050964
[2025-06-13 14:40:12,199] sft loss: 3.18359375, weighted bit mean: 3.62200927734375
[2025-06-13 14:40:12,199] bit.grad.mean: -0.000382 | norm: 0.042358
[2025-06-13 14:40:12,199] sft_loss.grad.mean: -0.000892 | norm: 0.044281
[2025-06-13 14:40:37,626] sft loss: 4.11328125, weighted bit mean: 3.622743879045759
[2025-06-13 14:41:48,972] sft loss: 3.5546875, weighted bit mean: 3.622743879045759
[2025-06-13 14:43:01,143] sft loss: 3.98828125, weighted bit mean: 3.622743879045759
[2025-06-13 14:44:13,434] sft loss: 2.275390625, weighted bit mean: 3.622743879045759
[2025-06-13 14:45:25,898] sft loss: 3.646484375, weighted bit mean: 3.622743879045759
[2025-06-13 14:46:37,648] sft loss: 3.251953125, weighted bit mean: 3.622743879045759
[2025-06-13 14:46:45,584] epoch 2:ori_model acc:0.771484375, quantized_model acc:0.74658203125 
[2025-06-13 14:46:45,584] Epoch 3
[2025-06-13 14:46:46,980] sft loss: 4.11328125, weighted bit mean: 3.622743879045759
[2025-06-13 14:46:46,980] bit.grad.mean: -0.000542 | norm: 0.061157
[2025-06-13 14:46:46,980] sft_loss.grad.mean: -0.001052 | norm: 0.062744
[2025-06-13 14:50:29,332] sft loss: 3.521484375, weighted bit mean: 3.6288604736328125
[2025-06-13 14:50:29,333] bit.grad.mean: 0.000187 | norm: 0.049194
[2025-06-13 14:50:29,333] sft_loss.grad.mean: -0.000324 | norm: 0.049652
[2025-06-13 14:54:14,220] sft loss: 3.96484375, weighted bit mean: 3.6356004987444197
[2025-06-13 14:54:14,220] bit.grad.mean: -0.000405 | norm: 0.053680
[2025-06-13 14:54:14,221] sft_loss.grad.mean: -0.000915 | norm: 0.055481
[2025-06-13 14:57:57,902] sft loss: 2.248046875, weighted bit mean: 3.642632620675223
[2025-06-13 14:57:57,902] bit.grad.mean: -0.000952 | norm: 0.041473
[2025-06-13 14:57:57,902] sft_loss.grad.mean: -0.001462 | norm: 0.045227
[2025-06-13 15:01:36,287] sft loss: 3.7421875, weighted bit mean: 3.649810791015625
[2025-06-13 15:01:36,287] bit.grad.mean: -0.000651 | norm: 0.064575
[2025-06-13 15:01:36,287] sft_loss.grad.mean: -0.001162 | norm: 0.066406
[2025-06-13 15:05:19,459] sft loss: 3.216796875, weighted bit mean: 3.6565660749162947
[2025-06-13 15:05:19,459] bit.grad.mean: -0.000417 | norm: 0.046143
[2025-06-13 15:05:19,459] sft_loss.grad.mean: -0.000927 | norm: 0.048004
[2025-06-13 15:05:44,857] sft loss: 4.0625, weighted bit mean: 3.6573704310825894
[2025-06-13 15:06:55,865] sft loss: 3.5625, weighted bit mean: 3.6573704310825894
[2025-06-13 15:08:07,677] sft loss: 4.00390625, weighted bit mean: 3.6573704310825894
[2025-06-13 15:09:19,466] sft loss: 2.27734375, weighted bit mean: 3.6573704310825894
[2025-06-13 15:10:29,860] sft loss: 3.6875, weighted bit mean: 3.6573704310825894
[2025-06-13 15:11:41,263] sft loss: 3.271484375, weighted bit mean: 3.6573704310825894
[2025-06-13 15:11:49,141] epoch 3:ori_model acc:0.771484375, quantized_model acc:0.75048828125 
[2025-06-13 15:11:49,141] Epoch 4
[2025-06-13 15:11:50,538] sft loss: 4.0625, weighted bit mean: 3.6573704310825894
[2025-06-13 15:11:50,538] bit.grad.mean: -0.000272 | norm: 0.062256
[2025-06-13 15:11:50,538] sft_loss.grad.mean: -0.000782 | norm: 0.063232
[2025-06-13 15:15:33,103] sft loss: 3.541015625, weighted bit mean: 3.6636221749441966
[2025-06-13 15:15:33,103] bit.grad.mean: -0.000128 | norm: 0.057098
[2025-06-13 15:15:33,103] sft_loss.grad.mean: -0.000638 | norm: 0.058380
[2025-06-13 15:19:18,257] sft loss: 3.978515625, weighted bit mean: 3.6707066127232144
[2025-06-13 15:19:18,257] bit.grad.mean: -0.000502 | norm: 0.050262
[2025-06-13 15:19:18,258] sft_loss.grad.mean: -0.001012 | norm: 0.052582
[2025-06-13 15:23:02,152] sft loss: 2.234375, weighted bit mean: 3.677313668387277
[2025-06-13 15:23:02,152] bit.grad.mean: -0.000806 | norm: 0.038483
[2025-06-13 15:23:02,152] sft_loss.grad.mean: -0.001316 | norm: 0.041962
[2025-06-13 15:26:40,698] sft loss: 3.662109375, weighted bit mean: 3.684297834123884
[2025-06-13 15:26:40,698] bit.grad.mean: 0.000127 | norm: 0.050537
[2025-06-13 15:26:40,698] sft_loss.grad.mean: -0.000383 | norm: 0.050964
[2025-06-13 15:30:23,825] sft loss: 3.26953125, weighted bit mean: 3.6905299595424106
[2025-06-13 15:30:23,825] bit.grad.mean: -0.001202 | norm: 0.060425
[2025-06-13 15:30:23,825] sft_loss.grad.mean: -0.001712 | norm: 0.063843
[2025-06-13 15:30:49,193] sft loss: 4.04296875, weighted bit mean: 3.691491263253348
[2025-06-13 15:32:00,595] sft loss: 3.51171875, weighted bit mean: 3.691491263253348
[2025-06-13 15:33:12,828] sft loss: 3.91796875, weighted bit mean: 3.691491263253348
[2025-06-13 15:34:25,121] sft loss: 2.2734375, weighted bit mean: 3.691491263253348
[2025-06-13 15:35:35,972] sft loss: 3.6796875, weighted bit mean: 3.691491263253348
[2025-06-13 15:36:47,850] sft loss: 3.23828125, weighted bit mean: 3.691491263253348
[2025-06-13 15:36:55,834] epoch 4:ori_model acc:0.771484375, quantized_model acc:0.7529296875 
[2025-06-13 15:36:55,834] Epoch 5
[2025-06-13 15:36:57,234] sft loss: 4.04296875, weighted bit mean: 3.691491263253348
[2025-06-13 15:36:57,234] bit.grad.mean: -0.000093 | norm: 0.065186
[2025-06-13 15:36:57,234] sft_loss.grad.mean: -0.000604 | norm: 0.065247
[2025-06-13 15:40:41,500] sft loss: 3.53515625, weighted bit mean: 3.697241646902902
[2025-06-13 15:40:41,501] bit.grad.mean: -0.000161 | norm: 0.057861
[2025-06-13 15:40:41,501] sft_loss.grad.mean: -0.000670 | norm: 0.059265
[2025-06-13 15:44:25,061] sft loss: 3.884765625, weighted bit mean: 3.7035326276506697
[2025-06-13 15:44:25,061] bit.grad.mean: 0.000001 | norm: 0.042389
[2025-06-13 15:44:25,061] sft_loss.grad.mean: -0.000509 | norm: 0.043579
[2025-06-13 15:48:10,673] sft loss: 2.26171875, weighted bit mean: 3.709714617047991
[2025-06-13 15:48:10,673] bit.grad.mean: -0.000776 | norm: 0.041473
[2025-06-13 15:48:10,673] sft_loss.grad.mean: -0.001287 | norm: 0.044556
[2025-06-13 15:51:49,993] sft loss: 3.654296875, weighted bit mean: 3.7164699009486606
[2025-06-13 15:51:49,993] bit.grad.mean: 0.000105 | norm: 0.048065
[2025-06-13 15:51:49,993] sft_loss.grad.mean: -0.000406 | norm: 0.048462
[2025-06-13 15:55:33,264] sft loss: 3.208984375, weighted bit mean: 3.7227042061941966
[2025-06-13 15:55:33,265] bit.grad.mean: -0.000202 | norm: 0.041321
[2025-06-13 15:55:33,265] sft_loss.grad.mean: -0.000712 | norm: 0.042725
[2025-06-13 15:55:58,614] sft loss: 4.11328125, weighted bit mean: 3.7232469831194197
[2025-06-13 15:57:09,948] sft loss: 3.525390625, weighted bit mean: 3.7232469831194197
[2025-06-13 15:58:22,163] sft loss: 3.94140625, weighted bit mean: 3.7232469831194197
[2025-06-13 15:59:34,925] sft loss: 2.248046875, weighted bit mean: 3.7232469831194197
[2025-06-13 16:00:46,955] sft loss: 3.66015625, weighted bit mean: 3.7232469831194197
[2025-06-13 16:01:58,787] sft loss: 3.23828125, weighted bit mean: 3.7232469831194197
[2025-06-13 16:02:06,714] epoch 5:ori_model acc:0.771484375, quantized_model acc:0.75732421875 
[2025-06-16 20:12:57,264] config: lr: 0.001, batch size:8, num epoches:16
[2025-06-16 20:12:57,264] loss: kld
[2025-06-16 20:12:57,264] origin bit
[2025-06-16 20:12:57,264] Epoch 1
[2025-06-16 20:12:58,973] sft loss: 4.15625, weighted bit mean: 3.505641392299107
[2025-06-16 20:12:58,985] bit.grad.mean: -0.001894 | norm: 0.085693
[2025-06-16 20:12:58,985] sft_loss.grad.mean: -0.001894 | norm: 0.085693
[2025-06-16 20:16:39,999] sft loss: 3.556640625, weighted bit mean: 3.520751953125
[2025-06-16 20:16:39,999] bit.grad.mean: -0.000492 | norm: 0.052795
[2025-06-16 20:16:39,999] sft_loss.grad.mean: -0.000492 | norm: 0.052795
[2025-06-16 20:20:23,753] sft loss: 3.90625, weighted bit mean: 3.53662109375
[2025-06-16 20:20:23,754] bit.grad.mean: -0.000627 | norm: 0.058075
[2025-06-16 20:20:23,754] sft_loss.grad.mean: -0.000627 | norm: 0.058075
[2025-06-16 20:24:07,861] sft loss: 2.21875, weighted bit mean: 3.553407941545759
[2025-06-16 20:24:07,861] bit.grad.mean: -0.001289 | norm: 0.044250
[2025-06-16 20:24:07,861] sft_loss.grad.mean: -0.001289 | norm: 0.044250
[2025-06-16 20:27:46,936] sft loss: 3.619140625, weighted bit mean: 3.569791521344866
[2025-06-16 20:27:46,936] bit.grad.mean: -0.000259 | norm: 0.045776
[2025-06-16 20:27:46,936] sft_loss.grad.mean: -0.000259 | norm: 0.045776
[2025-06-16 20:31:30,426] sft loss: 3.263671875, weighted bit mean: 3.586144583565848
[2025-06-16 20:31:30,426] bit.grad.mean: -0.001692 | norm: 0.059784
[2025-06-16 20:31:30,426] sft_loss.grad.mean: -0.001692 | norm: 0.059784
[2025-06-16 20:31:55,767] sft loss: 4.0390625, weighted bit mean: 3.588202340262277
[2025-06-16 20:33:06,905] sft loss: 3.546875, weighted bit mean: 3.588202340262277
[2025-06-16 20:34:18,872] sft loss: 3.92578125, weighted bit mean: 3.588202340262277
[2025-06-16 20:35:30,971] sft loss: 2.240234375, weighted bit mean: 3.588202340262277
[2025-06-16 20:36:41,643] sft loss: 3.615234375, weighted bit mean: 3.588202340262277
[2025-06-16 20:37:53,225] sft loss: 3.212890625, weighted bit mean: 3.588202340262277
[2025-06-16 20:38:01,187] epoch 1:ori_model acc:0.771484375, quantized_model acc:0.75634765625, weighted mean: 3.8448660714285716
[2025-06-16 20:38:01,187] epoch1: Quantized bit
[2025-06-16 20:38:01,187] Forwarding module: linear module0, using bit[0] = 2.6602
[2025-06-16 20:38:01,187] Forwarding module: linear module1, using bit[1] = 3.4316
[2025-06-16 20:38:01,187] Forwarding module: linear module2, using bit[2] = 4.7383
[2025-06-16 20:38:01,187] Forwarding module: linear module3, using bit[3] = 4.5703
[2025-06-16 20:38:01,187] Forwarding module: linear module4, using bit[4] = 3.3887
[2025-06-16 20:38:01,187] Forwarding module: linear module5, using bit[5] = 3.5273
[2025-06-16 20:38:01,187] Forwarding module: linear module6, using bit[6] = 4.5547
[2025-06-16 20:38:01,187] Forwarding module: linear module7, using bit[7] = 3.0059
[2025-06-16 20:38:01,187] Forwarding module: linear module8, using bit[8] = 3.5000
[2025-06-16 20:38:01,188] Forwarding module: linear module9, using bit[9] = 4.3203
[2025-06-16 20:38:01,188] Forwarding module: linear module10, using bit[10] = 3.9961
[2025-06-16 20:38:01,188] Forwarding module: linear module11, using bit[11] = 3.3594
[2025-06-16 20:38:01,188] Forwarding module: linear module12, using bit[12] = 3.5410
[2025-06-16 20:38:01,188] Forwarding module: linear module13, using bit[13] = 5.5000
[2025-06-16 20:38:01,188] Forwarding module: linear module14, using bit[14] = 4.0781
[2025-06-16 20:38:01,188] Forwarding module: linear module15, using bit[15] = 3.5059
[2025-06-16 20:38:01,188] Forwarding module: linear module16, using bit[16] = 4.4961
[2025-06-16 20:38:01,188] Forwarding module: linear module17, using bit[17] = 3.5391
[2025-06-16 20:38:01,188] Forwarding module: linear module18, using bit[18] = 3.2832
[2025-06-16 20:38:01,188] Forwarding module: linear module19, using bit[19] = 4.3555
[2025-06-16 20:38:01,188] Forwarding module: linear module20, using bit[20] = 3.6504
[2025-06-16 20:38:01,188] Forwarding module: linear module21, using bit[21] = 3.5176
[2025-06-16 20:38:01,188] Forwarding module: linear module22, using bit[22] = 4.2305
[2025-06-16 20:38:01,188] Forwarding module: linear module23, using bit[23] = 4.6211
[2025-06-16 20:38:01,188] Forwarding module: linear module24, using bit[24] = 3.4980
[2025-06-16 20:38:01,188] Forwarding module: linear module25, using bit[25] = 2.5957
[2025-06-16 20:38:01,188] Forwarding module: linear module26, using bit[26] = 3.5762
[2025-06-16 20:38:01,188] Forwarding module: linear module27, using bit[27] = 3.6152
[2025-06-16 20:38:01,188] Forwarding module: linear module28, using bit[28] = 3.1973
[2025-06-16 20:38:01,188] Forwarding module: linear module29, using bit[29] = 3.4980
[2025-06-16 20:38:01,189] Forwarding module: linear module30, using bit[30] = 4.2969
[2025-06-16 20:38:01,189] Forwarding module: linear module31, using bit[31] = 3.5293
[2025-06-16 20:38:01,189] Forwarding module: linear module32, using bit[32] = 3.5430
[2025-06-16 20:38:01,189] Forwarding module: linear module33, using bit[33] = 3.5645
[2025-06-16 20:38:01,189] Forwarding module: linear module34, using bit[34] = 3.6230
[2025-06-16 20:38:01,189] Forwarding module: linear module35, using bit[35] = 3.5977
[2025-06-16 20:38:01,189] Forwarding module: linear module36, using bit[36] = 3.5371
[2025-06-16 20:38:01,189] Forwarding module: linear module37, using bit[37] = 4.1719
[2025-06-16 20:38:01,189] Forwarding module: linear module38, using bit[38] = 3.5176
[2025-06-16 20:38:01,189] Forwarding module: linear module39, using bit[39] = 2.9805
[2025-06-16 20:38:01,189] Forwarding module: linear module40, using bit[40] = 3.5879
[2025-06-16 20:38:01,189] Forwarding module: linear module41, using bit[41] = 3.6895
[2025-06-16 20:38:01,189] Forwarding module: linear module42, using bit[42] = 3.5000
[2025-06-16 20:38:01,189] Forwarding module: linear module43, using bit[43] = 4.0742
[2025-06-16 20:38:01,189] Forwarding module: linear module44, using bit[44] = 4.5703
[2025-06-16 20:38:01,189] Forwarding module: linear module45, using bit[45] = 3.5234
[2025-06-16 20:38:01,189] Forwarding module: linear module46, using bit[46] = 3.6250
[2025-06-16 20:38:01,189] Forwarding module: linear module47, using bit[47] = 3.6230
[2025-06-16 20:38:01,189] Forwarding module: linear module48, using bit[48] = 3.6113
[2025-06-16 20:38:01,189] Forwarding module: linear module49, using bit[49] = 2.8691
[2025-06-16 20:38:01,189] Forwarding module: linear module50, using bit[50] = 2.7754
[2025-06-16 20:38:01,189] Forwarding module: linear module51, using bit[51] = 3.8281
[2025-06-16 20:38:01,189] Forwarding module: linear module52, using bit[52] = 4.4961
[2025-06-16 20:38:01,190] Forwarding module: linear module53, using bit[53] = 3.4961
[2025-06-16 20:38:01,190] Forwarding module: linear module54, using bit[54] = 3.5625
[2025-06-16 20:38:01,190] Forwarding module: linear module55, using bit[55] = 3.8965
[2025-06-16 20:38:01,190] Forwarding module: linear module56, using bit[56] = 3.5117
[2025-06-16 20:38:01,190] Forwarding module: linear module57, using bit[57] = 3.6113
[2025-06-16 20:38:01,190] Forwarding module: linear module58, using bit[58] = 4.2773
[2025-06-16 20:38:01,190] Forwarding module: linear module59, using bit[59] = 3.5000
[2025-06-16 20:38:01,190] Forwarding module: linear module60, using bit[60] = 3.1621
[2025-06-16 20:38:01,190] Forwarding module: linear module61, using bit[61] = 3.5098
[2025-06-16 20:38:01,190] Forwarding module: linear module62, using bit[62] = 3.5938
[2025-06-16 20:38:01,190] Forwarding module: linear module63, using bit[63] = 3.4629
[2025-06-16 20:38:01,190] Forwarding module: linear module64, using bit[64] = 3.5176
[2025-06-16 20:38:01,190] Forwarding module: linear module65, using bit[65] = 3.7871
[2025-06-16 20:38:01,190] Forwarding module: linear module66, using bit[66] = 4.6094
[2025-06-16 20:38:01,190] Forwarding module: linear module67, using bit[67] = 2.5977
[2025-06-16 20:38:01,190] Forwarding module: linear module68, using bit[68] = 3.2891
[2025-06-16 20:38:01,190] Forwarding module: linear module69, using bit[69] = 3.5859
[2025-06-16 20:38:01,190] Forwarding module: linear module70, using bit[70] = 3.5020
[2025-06-16 20:38:01,190] Forwarding module: linear module71, using bit[71] = 3.8711
[2025-06-16 20:38:01,190] Forwarding module: linear module72, using bit[72] = 4.2266
[2025-06-16 20:38:01,190] Forwarding module: linear module73, using bit[73] = 4.6172
[2025-06-16 20:38:01,190] Forwarding module: linear module74, using bit[74] = 3.2754
[2025-06-16 20:38:01,191] Forwarding module: linear module75, using bit[75] = 3.6152
[2025-06-16 20:38:01,191] Forwarding module: linear module76, using bit[76] = 4.5820
[2025-06-16 20:38:01,191] Forwarding module: linear module77, using bit[77] = 3.6035
[2025-06-16 20:38:01,191] Forwarding module: linear module78, using bit[78] = 4.2539
[2025-06-16 20:38:01,191] Forwarding module: linear module79, using bit[79] = 4.5000
[2025-06-16 20:38:01,191] Forwarding module: linear module80, using bit[80] = 3.6328
[2025-06-16 20:38:01,191] Forwarding module: linear module81, using bit[81] = 3.5059
[2025-06-16 20:38:01,191] Forwarding module: linear module82, using bit[82] = 3.4668
[2025-06-16 20:38:01,191] Forwarding module: linear module83, using bit[83] = 3.5078
[2025-06-16 20:38:01,191] Forwarding module: linear module84, using bit[84] = 3.0605
[2025-06-16 20:38:01,191] Forwarding module: linear module85, using bit[85] = 3.5664
[2025-06-16 20:38:01,191] Forwarding module: linear module86, using bit[86] = 4.5000
[2025-06-16 20:38:01,191] Forwarding module: linear module87, using bit[87] = 3.9180
[2025-06-16 20:38:01,191] Forwarding module: linear module88, using bit[88] = 2.7090
[2025-06-16 20:38:01,191] Forwarding module: linear module89, using bit[89] = 3.6035
[2025-06-16 20:38:01,191] Forwarding module: linear module90, using bit[90] = 3.5039
[2025-06-16 20:38:01,191] Forwarding module: linear module91, using bit[91] = 3.5625
[2025-06-16 20:38:01,191] Forwarding module: linear module92, using bit[92] = 3.5000
[2025-06-16 20:38:01,191] Forwarding module: linear module93, using bit[93] = 5.1797
[2025-06-16 20:38:01,191] Forwarding module: linear module94, using bit[94] = 3.5508
[2025-06-16 20:38:01,191] Forwarding module: linear module95, using bit[95] = 3.5098
[2025-06-16 20:38:01,191] Forwarding module: linear module96, using bit[96] = 3.4980
[2025-06-16 20:38:01,192] Forwarding module: linear module97, using bit[97] = 3.5801
[2025-06-16 20:38:01,192] Forwarding module: linear module98, using bit[98] = 3.6113
[2025-06-16 20:38:01,192] Forwarding module: linear module99, using bit[99] = 3.2852
[2025-06-16 20:38:01,192] Forwarding module: linear module100, using bit[100] = 4.5234
[2025-06-16 20:38:01,192] Forwarding module: linear module101, using bit[101] = 4.0742
[2025-06-16 20:38:01,192] Forwarding module: linear module102, using bit[102] = 3.6543
[2025-06-16 20:38:01,192] Forwarding module: linear module103, using bit[103] = 3.5254
[2025-06-16 20:38:01,192] Forwarding module: linear module104, using bit[104] = 3.5938
[2025-06-16 20:38:01,192] Forwarding module: linear module105, using bit[105] = 3.2207
[2025-06-16 20:38:01,192] Forwarding module: linear module106, using bit[106] = 3.6152
[2025-06-16 20:38:01,192] Forwarding module: linear module107, using bit[107] = 4.6797
[2025-06-16 20:38:01,192] Forwarding module: linear module108, using bit[108] = 3.6328
[2025-06-16 20:38:01,192] Forwarding module: linear module109, using bit[109] = 3.5859
[2025-06-16 20:38:01,192] Forwarding module: linear module110, using bit[110] = 3.5000
[2025-06-16 20:38:01,192] Forwarding module: linear module111, using bit[111] = 3.8496
[2025-06-16 20:38:01,192] Forwarding module: linear module112, using bit[112] = 3.5234
[2025-06-16 20:38:01,192] Forwarding module: linear module113, using bit[113] = 3.5000
[2025-06-16 20:38:01,192] Forwarding module: linear module114, using bit[114] = 3.5469
[2025-06-16 20:38:01,192] Forwarding module: linear module115, using bit[115] = 3.3535
[2025-06-16 20:38:01,192] Forwarding module: linear module116, using bit[116] = 3.5117
[2025-06-16 20:38:01,192] Forwarding module: linear module117, using bit[117] = 3.6055
[2025-06-16 20:38:01,192] Forwarding module: linear module118, using bit[118] = 4.3203
[2025-06-16 20:38:01,193] Forwarding module: linear module119, using bit[119] = 2.7695
[2025-06-16 20:38:01,193] Forwarding module: linear module120, using bit[120] = 3.5332
[2025-06-16 20:38:01,193] Forwarding module: linear module121, using bit[121] = 2.7305
[2025-06-16 20:38:01,193] Forwarding module: linear module122, using bit[122] = 2.6211
[2025-06-16 20:38:01,193] Forwarding module: linear module123, using bit[123] = 3.6562
[2025-06-16 20:38:01,193] Forwarding module: linear module124, using bit[124] = 3.5176
[2025-06-16 20:38:01,193] Forwarding module: linear module125, using bit[125] = 3.6445
[2025-06-16 20:38:01,193] Forwarding module: linear module126, using bit[126] = 3.1504
[2025-06-16 20:38:01,193] Forwarding module: linear module127, using bit[127] = 4.0898
[2025-06-16 20:38:01,193] Forwarding module: linear module128, using bit[128] = 5.3320
[2025-06-16 20:38:01,193] Forwarding module: linear module129, using bit[129] = 3.5391
[2025-06-16 20:38:01,193] Forwarding module: linear module130, using bit[130] = 3.4492
[2025-06-16 20:38:01,193] Forwarding module: linear module131, using bit[131] = 3.5527
[2025-06-16 20:38:01,193] Forwarding module: linear module132, using bit[132] = 3.5840
[2025-06-16 20:38:01,193] Forwarding module: linear module133, using bit[133] = 3.5293
[2025-06-16 20:38:01,193] Forwarding module: linear module134, using bit[134] = 3.5020
[2025-06-16 20:38:01,193] Forwarding module: linear module135, using bit[135] = 3.5098
[2025-06-16 20:38:01,193] Forwarding module: linear module136, using bit[136] = 3.5156
[2025-06-16 20:38:01,193] Forwarding module: linear module137, using bit[137] = 3.6094
[2025-06-16 20:38:01,193] Forwarding module: linear module138, using bit[138] = 3.3926
[2025-06-16 20:38:01,193] Forwarding module: linear module139, using bit[139] = 3.6914
[2025-06-16 20:38:01,193] Forwarding module: linear module140, using bit[140] = 3.0312
[2025-06-16 20:38:01,193] Forwarding module: linear module141, using bit[141] = 3.5742
[2025-06-16 20:38:01,194] Forwarding module: linear module142, using bit[142] = 4.5273
[2025-06-16 20:38:01,194] Forwarding module: linear module143, using bit[143] = 2.8672
[2025-06-16 20:38:01,194] Forwarding module: linear module144, using bit[144] = 3.2266
[2025-06-16 20:38:01,194] Forwarding module: linear module145, using bit[145] = 3.5938
[2025-06-16 20:38:01,194] Forwarding module: linear module146, using bit[146] = 3.6816
[2025-06-16 20:38:01,194] Forwarding module: linear module147, using bit[147] = 3.6582
[2025-06-16 20:38:01,194] Forwarding module: linear module148, using bit[148] = 3.1621
[2025-06-16 20:38:01,194] Forwarding module: linear module149, using bit[149] = 4.6602
[2025-06-16 20:38:01,194] Forwarding module: linear module150, using bit[150] = 3.5000
[2025-06-16 20:38:01,194] Forwarding module: linear module151, using bit[151] = 2.5977
[2025-06-16 20:38:01,194] Forwarding module: linear module152, using bit[152] = 2.5137
[2025-06-16 20:38:01,194] Forwarding module: linear module153, using bit[153] = 3.6504
[2025-06-16 20:38:01,194] Forwarding module: linear module154, using bit[154] = 3.5000
[2025-06-16 20:38:01,194] Forwarding module: linear module155, using bit[155] = 4.1836
[2025-06-16 20:38:01,194] Forwarding module: linear module156, using bit[156] = 4.3320
[2025-06-16 20:38:01,194] Forwarding module: linear module157, using bit[157] = 3.7500
[2025-06-16 20:38:01,194] Forwarding module: linear module158, using bit[158] = 3.5547
[2025-06-16 20:38:01,194] Forwarding module: linear module159, using bit[159] = 3.6543
[2025-06-16 20:38:01,194] Forwarding module: linear module160, using bit[160] = 3.5488
[2025-06-16 20:38:01,194] Forwarding module: linear module161, using bit[161] = 2.5000
[2025-06-16 20:38:01,194] Forwarding module: linear module162, using bit[162] = 3.5000
[2025-06-16 20:38:01,194] Forwarding module: linear module163, using bit[163] = 4.6055
[2025-06-16 20:38:01,194] Forwarding module: linear module164, using bit[164] = 3.6191
[2025-06-16 20:38:01,195] Forwarding module: linear module165, using bit[165] = 3.5879
[2025-06-16 20:38:01,195] Forwarding module: linear module166, using bit[166] = 3.4258
[2025-06-16 20:38:01,195] Forwarding module: linear module167, using bit[167] = 3.6602
[2025-06-16 20:38:01,195] Forwarding module: linear module168, using bit[168] = 3.1113
[2025-06-16 20:38:01,195] Forwarding module: linear module169, using bit[169] = 3.5742
[2025-06-16 20:38:01,195] Forwarding module: linear module170, using bit[170] = 3.4980
[2025-06-16 20:38:01,195] Forwarding module: linear module171, using bit[171] = 3.5020
[2025-06-16 20:38:01,195] Forwarding module: linear module172, using bit[172] = 3.5039
[2025-06-16 20:38:01,195] Forwarding module: linear module173, using bit[173] = 3.5000
[2025-06-16 20:38:01,195] Forwarding module: linear module174, using bit[174] = 4.5039
[2025-06-16 20:38:01,195] Forwarding module: linear module175, using bit[175] = 3.0840
[2025-06-16 20:38:01,195] Forwarding module: linear module176, using bit[176] = 3.5977
[2025-06-16 20:38:01,195] Forwarding module: linear module177, using bit[177] = 5.5000
[2025-06-16 20:38:01,195] Forwarding module: linear module178, using bit[178] = 3.6484
[2025-06-16 20:38:01,195] Forwarding module: linear module179, using bit[179] = 3.6836
[2025-06-16 20:38:01,195] Forwarding module: linear module180, using bit[180] = 2.5195
[2025-06-16 20:38:01,195] Forwarding module: linear module181, using bit[181] = 3.6816
[2025-06-16 20:38:01,195] Forwarding module: linear module182, using bit[182] = 3.5312
[2025-06-16 20:38:01,195] Forwarding module: linear module183, using bit[183] = 3.5000
[2025-06-16 20:38:01,195] Forwarding module: linear module184, using bit[184] = 4.5586
[2025-06-16 20:38:01,195] Forwarding module: linear module185, using bit[185] = 4.5000
[2025-06-16 20:38:01,196] Forwarding module: linear module186, using bit[186] = 3.5039
[2025-06-16 20:38:01,196] Forwarding module: linear module187, using bit[187] = 3.6055
[2025-06-16 20:38:01,196] Forwarding module: linear module188, using bit[188] = 3.6172
[2025-06-16 20:38:01,196] Forwarding module: linear module189, using bit[189] = 3.6523
[2025-06-16 20:38:01,196] Forwarding module: linear module190, using bit[190] = 3.6406
[2025-06-16 20:38:01,196] Forwarding module: linear module191, using bit[191] = 5.1992
[2025-06-16 20:38:01,196] Forwarding module: linear module192, using bit[192] = 4.5000
[2025-06-16 20:38:01,196] Forwarding module: linear module193, using bit[193] = 3.6289
[2025-06-16 20:38:01,196] Forwarding module: linear module194, using bit[194] = 3.5605
[2025-06-16 20:38:01,196] Forwarding module: linear module195, using bit[195] = 4.5078
[2025-06-16 20:38:01,196] epoch 1:ori_model acc: 0.771484375, quantized_model acc: 0.75634765625, bit mean: 3.8448660714285716
[2025-06-16 20:38:01,196] time used is 1503.931728363037
